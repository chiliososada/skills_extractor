# final_fix_resume_extractor_v1.py - ä¼˜åŒ–æŠ€æœ¯å…³é”®å­—æå–é€»è¾‘
# -*- coding: utf-8 -*-

import pandas as pd
import numpy as np
import re
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Union, Tuple, Set
from collections import defaultdict, Counter


class FinalFixResumeExtractor:
    """æœ€ç»ˆä¿®å¤ç‰ˆç®€å†æå–å™¨ - ä¼˜åŒ–æŠ€æœ¯å…³é”®å­—æå–é€»è¾‘"""

    def __init__(self):
        self.template = {
            "name": "",
            "gender": None,
            "age": "",
            "nationality": None,
            "arrival_year_japan": None,
            "skills": [],
            "experience": "",
            "japanese_level": "",
        }

        # å…¨è§’è½¬åŠè§’çš„è½¬æ¢è¡¨
        self.trans_table = str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™", "0123456789")

        # æ‰©å±•çš„æŠ€èƒ½æ ‡è®°ç¬¦å·
        self.skill_marks = ["â—", "â—‹", "â–³", "Ã—", "â˜…", "â—", "â—¯", "â–²", "â€»"]

        # Excelæ—¥æœŸèµ·å§‹ç‚¹ï¼š1900å¹´1æœˆ1æ—¥
        self.excel_epoch = datetime(1900, 1, 1)

        # çœŸæ­£çš„æŠ€èƒ½å…³é”®è¯ï¼ˆæ ‡å‡†åŒ–åçš„åç§°ï¼‰
        self.valid_skills = {
            # ç¼–ç¨‹è¯­è¨€
            "Java",
            "Python",
            "JavaScript",
            "TypeScript",
            "C",
            "C++",
            "C#",
            "C/C++",
            "PHP",
            "Ruby",
            "Go",
            "Kotlin",
            "Swift",
            "Scala",
            "Rust",
            "VB.NET",
            "VB",
            "VBA",
            "COBOL",
            "Perl",
            "R",
            "Objective-C",
            # å‰ç«¯
            "HTML",
            "HTML5",
            "CSS",
            "CSS3",
            "React",
            "React.js",
            "Vue",
            "Vue.js",
            "Angular",
            "jQuery",
            "Bootstrap",
            "Webpack",
            "Sass",
            "Less",
            # åç«¯æ¡†æ¶
            "Spring",
            "SpringBoot",
            "SpringMVC",
            "Struts",
            "Struts2",
            "Django",
            "Flask",
            "Rails",
            "Express",
            "Node.js",
            ".NET",
            "ASP.NET",
            "Laravel",
            "Thymeleaf",
            "JSF",
            "JSP",
            "Servlet",
            "Java Servlet",
            "Hibernate",
            "MyBatis",
            "Mybatis",
            "JPA",
            # æ•°æ®åº“
            "MySQL",
            "PostgreSQL",
            "Oracle",
            "SQL Server",
            "SQLServer",
            "MongoDB",
            "Redis",
            "DB2",
            "SQLite",
            "Access",
            "Sybase",
            "Azure SQL DB",
            "PL/SQL",
            "Aurora",
            # å·¥å…·å’Œå¹³å°
            "AWS",
            "Azure",
            "GCP",
            "Docker",
            "Kubernetes",
            "Git",
            "GitHub",
            "GitLab",
            "SVN",
            "TortoiseSVN",
            "Jenkins",
            "Maven",
            "Gradle",
            # OS
            "Windows",
            "Windows 10",
            "Linux",
            "Unix",
            "Solaris",
            "DOS/V",
            "Win95/98",
            "win10",
            "Ubuntu",
            "CentOS",
            "RedHat",
            # æœåŠ¡å™¨
            "Apache",
            "Nginx",
            "Tomcat",
            "WebSphere",
            "JBoss",
            "JBOSS",
            "IIS",
            # IDEå’Œå·¥å…·
            "Eclipse",
            "IntelliJ",
            "VS Code",
            "Visual Studio",
            "Android Studio",
            "NetBeans",
            "Xcode",
            "A5M2",
            "WinMerge",
            "WinSCP",
            "Sourcetree",
            "Postman",
            "Fiddler",
            "Charles",
            "Form Designer",
            # æµ‹è¯•å·¥å…·
            "JUnit",
            "Junit",
            "Selenium",
            "JMeter",
            "Jmeter",
            "Spock",
            # å…¶ä»–æŠ€æœ¯
            "XML",
            "JSON",
            "REST",
            "SOAP",
            "Ajax",
            "Microservices",
            "Shell",
            "Bash",
            "PowerShell",
            "VBScript",
            # ç§»åŠ¨å¼€å‘
            "Android",
            "iOS",
            "React Native",
            "Flutter",
            # å…¶ä»–æ¡†æ¶å’Œåº“
            "TERASOLUNA",
            "OutSystems",
            "Wacs",
            # è¯­è¨€ï¼ˆç‰¹æ®Šå¤„ç†ï¼‰
            "æ—¥æœ¬èª",
            "è‹±èª",
            "ä¸­å›½èª",
            # Webç›¸å…³
            "PHP/HTML",
            "Jquery",
        }

        # éœ€è¦æ’é™¤çš„éæŠ€èƒ½å†…å®¹
        self.exclude_patterns = [
            r"^\d{4}[-/]\d{2}[-/]\d{2}",
            r"^\d{2,4}å¹´\d{1,2}æœˆ",
            r"\d+äºº",
            r"äººä»¥[ä¸‹ä¸Š]",
            r"^(åŸºæœ¬|è©³ç´°)è¨­è¨ˆ$",
            r"^è£½é€ $",
            r"^(å˜ä½“|çµåˆ|ç·åˆ|é‹ç”¨)[è©¦é¨“ãƒ†ã‚¹ãƒˆ]",
            r"^ä¿å®ˆé‹ç”¨$",
            r"^è¦ä»¶å®šç¾©$",
            r"^(SE|PG|PL|PM|TL)$",
            r"^ç®¡ç†$",
            r"ç®¡ç†çµŒé¨“",
            r"^æ•™\s*è‚²$",
            r"æ¥­å‹™çµŒæ­´",
            r"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ",
            r"^ãã®ä»–$",
            r"^éå»ã®",
            r"ã€.*ã€‘",
            r"^[A-BD-Z]$",
            r"^æºå¸¯$",
            r"^E-mail$",
        ]

        # å…³é”®è¯å®šä¹‰
        self.keywords = {
            "name": ["æ°å", "æ° å", "åå‰", "ãƒ•ãƒªã‚¬ãƒŠ", "Name", "åã€€å‰", "å§“å"],
            "age": [
                "å¹´é½¢",
                "å¹´é¾„",
                "å¹´ä»¤",
                "æ­³",
                "æ‰",
                "Age",
                "å¹´ã€€é½¢",
                "ç”Ÿå¹´æœˆ",
                "æº€",
            ],
            "gender": ["æ€§åˆ¥", "æ€§åˆ«", "Gender", "æ€§ã€€åˆ¥"],
            "nationality": ["å›½ç±", "å‡ºèº«å›½", "å‡ºèº«åœ°", "Nationality", "å›½ã€€ç±"],
            "experience": [
                "çµŒé¨“å¹´æ•°",
                "å®Ÿå‹™çµŒé¨“",
                "é–‹ç™ºçµŒé¨“",
                "ã‚½ãƒ•ãƒˆé–¢é€£æ¥­å‹™çµŒé¨“å¹´æ•°",
                "ITçµŒé¨“",
                "æ¥­å‹™çµŒé¨“",
                "çµŒé¨“",
                "å®Ÿå‹™å¹´æ•°",
                "Experience",
                "ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢çµŒé¨“",
                "çµŒé¨“å¹´æœˆ",
                "è·æ­´",
                "ITçµŒé¨“å¹´æ•°",
                "ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã‚½ãƒ•ãƒˆã‚¦ã‚¨ã‚¢é–¢é€£æ¥­å‹™",
                "å®Ÿå‹™å¹´æ•°",
            ],
            "arrival": [
                "æ¥æ—¥",
                "æ¸¡æ—¥",
                "å…¥å›½",
                "æ—¥æœ¬æ»åœ¨å¹´æ•°",
                "æ»åœ¨å¹´æ•°",
                "åœ¨æ—¥å¹´æ•°",
                "æ¥æ—¥å¹´",
                "æ¥æ—¥æ™‚æœŸ",
                "æ¥æ—¥å¹´æœˆ",
                "æ¥æ—¥å¹´åº¦",
            ],
            "japanese": [
                "æ—¥æœ¬èª",
                "æ—¥èª",
                "JLPT",
                "æ—¥æœ¬èªèƒ½åŠ›",
                "èªå­¦åŠ›",
                "è¨€èªèƒ½åŠ›",
                "æ—¥æœ¬èªãƒ¬ãƒ™ãƒ«",
                "Japanese",
            ],
            "education": [
                "å­¦æ­´",
                "å­¦æ ¡",
                "å¤§å­¦",
                "å’æ¥­",
                "å°‚é–€å­¦æ ¡",
                "é«˜æ ¡",
                "æœ€çµ‚å­¦æ­´",
            ],
            "skills": [
                "æŠ€è¡“",
                "ã‚¹ã‚­ãƒ«",
                "è¨€èª",
                "DB",
                "OS",
                "ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯",
                "ãƒ„ãƒ¼ãƒ«",
                "Skills",
                "å¼€å‘è¯­è¨€",
                "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èª",
                "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹",
                "é–‹ç™ºç’°å¢ƒ",
                "æŠ€è¡“çµŒé¨“",
            ],
        }

    def extract_from_excel(self, file_path: str) -> Dict:
        """ä»Excelæ–‡ä»¶æå–ç®€å†ä¿¡æ¯"""
        try:
            # è¯»å–æ‰€æœ‰sheets
            all_sheets = pd.read_excel(file_path, sheet_name=None)

            result = self.template.copy()

            # æ”¶é›†æ‰€æœ‰æ•°æ®
            all_data = []
            for sheet_name, df in all_sheets.items():
                all_data.append(
                    {
                        "sheet_name": sheet_name,
                        "df": df,
                        "text": self._dataframe_to_text(df),
                    }
                )

            # æå–å„ä¸ªå­—æ®µ
            result["name"] = self._extract_name(all_data)
            result["gender"] = self._extract_gender(all_data)
            result["age"] = self._extract_age_final_fix(all_data)
            result["nationality"] = self._extract_nationality_final_fix(all_data)
            result["arrival_year_japan"] = self._extract_arrival_year_final_fix(
                all_data
            )
            result["experience"] = self._extract_experience_final_fix(all_data)
            result["japanese_level"] = self._extract_japanese_level(all_data)
            result["skills"] = self._extract_skills_v1(all_data)  # ä½¿ç”¨æ–°çš„æå–æ–¹æ³•

            return result

        except Exception as e:
            print(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            import traceback

            traceback.print_exc()
            return {"error": str(e)}

    def _extract_skills_v1(self, all_data: List[Dict]) -> List[str]:
        """åŸºäºè¡¨æ ¼ç»“æ„çš„æŠ€æœ¯å…³é”®å­—æå–V1ç‰ˆ"""
        all_skills = []

        for data in all_data:
            df = data["df"]

            print(f"ğŸ” å¼€å§‹æŠ€æœ¯å…³é”®å­—æå–V1...")

            # Step 1: æ‰¾åˆ°"åŸºæœ¬è¨­è¨ˆ"å’Œ"è©³ç´°è¨­è¨ˆ"æ‰€åœ¨çš„ä½ç½®
            design_positions = self._find_design_columns(df)
            if not design_positions:
                print(f"    æœªæ‰¾åˆ°åŸºæœ¬è¨­è¨ˆ/è©³ç´°è¨­è¨ˆåˆ—ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
                # å¦‚æœæ‰¾ä¸åˆ°è®¾è®¡åˆ—ï¼Œä½¿ç”¨å¤‡ç”¨æå–æ–¹æ³•
                all_skills.extend(self._extract_skills_fallback(df))
                continue

            print(f"    æ‰¾åˆ°è®¾è®¡åˆ—ä½ç½®: {len(design_positions)}ä¸ª")

            # Step 2: åœ¨è®¾è®¡åˆ—ä¹‹åçš„è¡Œä¸­æŸ¥æ‰¾æŠ€æœ¯å…³é”®å­—èµ·å§‹è¡Œ
            skill_start_position = self._find_skill_start_row(df, design_positions)
            if not skill_start_position:
                print(f"    æœªæ‰¾åˆ°æŠ€æœ¯å…³é”®å­—èµ·å§‹è¡Œï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
                all_skills.extend(self._extract_skills_fallback(df))
                continue

            print(
                f"    æŠ€æœ¯å…³é”®å­—èµ·å§‹ä½ç½®: è¡Œ{skill_start_position['row']}, åˆ—{skill_start_position['col']}"
            )

            # Step 3: ä»èµ·å§‹ä½ç½®å‘ä¸‹æå–æ•´åˆ—çš„æŠ€æœ¯å…³é”®å­—
            skills = self._extract_skills_from_column(df, skill_start_position)
            all_skills.extend(skills)

        # å»é‡å’Œæ ‡å‡†åŒ–
        final_skills = self._process_and_deduplicate_skills(all_skills)
        return final_skills

    def _find_design_columns(self, df: pd.DataFrame) -> List[Dict]:
        """æŸ¥æ‰¾åŸºæœ¬è¨­è¨ˆå’Œè©³ç´°è¨­è¨ˆæ‰€åœ¨çš„åˆ—"""
        design_keywords = ["åŸºæœ¬è¨­è¨ˆ", "è©³ç´°è¨­è¨ˆ", "åŸºæœ¬è®¾è®¡", "è¯¦ç»†è®¾è®¡"]
        positions = []

        # éå†æ‰€æœ‰å•å…ƒæ ¼æŸ¥æ‰¾è®¾è®¡å…³é”®è¯
        for idx in range(min(len(df), 100)):  # é™åˆ¶æœç´¢èŒƒå›´
            for col in range(len(df.columns)):
                cell = df.iloc[idx, col]
                if pd.notna(cell):
                    cell_str = str(cell).strip()
                    if any(keyword in cell_str for keyword in design_keywords):
                        positions.append({"row": idx, "col": col, "value": cell_str})
                        print(f"      æ‰¾åˆ°è®¾è®¡å…³é”®è¯: [{idx},{col}] = {cell_str}")

        return positions

    def _find_skill_start_row(
        self, df: pd.DataFrame, design_positions: List[Dict]
    ) -> Optional[Dict]:
        """åœ¨è®¾è®¡åˆ—ä¹‹åæŸ¥æ‰¾æŠ€æœ¯å…³é”®å­—èµ·å§‹è¡Œ"""
        if not design_positions:
            return None

        # è·å–æœ€åä¸€ä¸ªè®¾è®¡å…³é”®è¯çš„è¡Œå·
        last_design_row = max(pos["row"] for pos in design_positions)

        # è·å–è®¾è®¡åˆ—çš„åˆ—å·èŒƒå›´ï¼ˆé€šå¸¸æŠ€æœ¯å…³é”®å­—åœ¨å·¦ä¾§ï¼‰
        design_cols = [pos["col"] for pos in design_positions]
        min_design_col = min(design_cols)

        print(f"    ä»è¡Œ {last_design_row + 1} å¼€å§‹æŸ¥æ‰¾æŠ€æœ¯å…³é”®å­—")

        # ä»è®¾è®¡è¡Œä¹‹åå¼€å§‹æŸ¥æ‰¾
        for row in range(last_design_row + 1, min(len(df), last_design_row + 30)):
            # ä¼˜å…ˆæŸ¥æ‰¾è®¾è®¡åˆ—å·¦ä¾§çš„å•å…ƒæ ¼
            for col in range(
                0, min(len(df.columns), min_design_col + 5)
            ):  # ä¹Ÿæ£€æŸ¥å³ä¾§ä¸€äº›åˆ—
                cell = df.iloc[row, col]
                if pd.notna(cell):
                    cell_str = str(cell).strip()

                    # æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰æ•ˆçš„æŠ€æœ¯å…³é”®å­—
                    found_skills = self._check_cell_contains_skills(cell_str)
                    if found_skills:
                        print(
                            f"      åœ¨ [{row},{col}] æ‰¾åˆ°æŠ€æœ¯å…³é”®å­—: {', '.join(found_skills[:3])}..."
                        )
                        return {"row": row, "col": col, "found_skills": found_skills}

        return None

    def _check_cell_contains_skills(self, cell_content: str) -> List[str]:
        """æ£€æŸ¥å•å…ƒæ ¼å†…å®¹æ˜¯å¦åŒ…å«æŠ€æœ¯å…³é”®å­—"""
        found_skills = []

        # åˆ†å‰²å•å…ƒæ ¼å†…å®¹ï¼ˆå¤„ç†æ¢è¡Œå’Œã€åˆ†å‰²ï¼‰
        potential_skills = re.split(r"[\n\rã€,ï¼Œ\t]+", cell_content)

        for item in potential_skills:
            item = item.strip()
            if item:
                # ç§»é™¤å¯èƒ½çš„æ ‡è®°ç¬¦å·
                item = re.sub(r"^[â—â—‹â–³Ã—â˜…â—â—¯â–²â€»]\s*", "", item)

                # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆæŠ€èƒ½
                normalized = self._normalize_skill_name(item)
                if normalized in self.valid_skills:
                    found_skills.append(normalized)
                # ä¹Ÿæ£€æŸ¥åŸå§‹å½¢å¼
                elif self._is_valid_skill(item):
                    found_skills.append(item)

        return found_skills

    def _extract_skills_from_column(
        self, df: pd.DataFrame, start_position: Dict
    ) -> List[str]:
        """ä»æŒ‡å®šä½ç½®å‘ä¸‹æå–æ•´åˆ—çš„æŠ€æœ¯å…³é”®å­—"""
        skills = []
        start_row = start_position["row"]
        start_col = start_position["col"]

        print(f"    ä»åˆ— {start_col} æå–æŠ€æœ¯å…³é”®å­—ï¼ˆèµ·å§‹è¡Œ: {start_row}ï¼‰")

        # è®°å½•å·²å¤„ç†çš„åˆå¹¶å•å…ƒæ ¼
        processed_cells = set()

        # å‘ä¸‹éå†æ•´åˆ—
        for row in range(start_row, len(df)):
            # æ£€æŸ¥ä¸»åˆ—å’Œç›¸é‚»åˆ—ï¼ˆè€ƒè™‘åˆå¹¶å•å…ƒæ ¼å¯èƒ½è·¨åˆ—ï¼‰
            for col_offset in range(-2, 3):
                col = start_col + col_offset
                if 0 <= col < len(df.columns):
                    cell = df.iloc[row, col]

                    # è·³è¿‡å·²å¤„ç†çš„å•å…ƒæ ¼
                    cell_key = f"{row},{col}"
                    if cell_key in processed_cells:
                        continue

                    if pd.notna(cell):
                        cell_str = str(cell).strip()

                        # æ’é™¤æ˜æ˜¾ä¸æ˜¯æŠ€èƒ½çš„å†…å®¹
                        if self._is_skill_section_end(cell_str):
                            print(
                                f"      åœ¨è¡Œ {row} é‡åˆ°æŠ€èƒ½åŒºåŸŸç»“æŸæ ‡è®°: {cell_str[:20]}..."
                            )
                            if col == start_col:  # åªæœ‰ä¸»åˆ—çš„ç»“æŸæ ‡è®°æ‰åœæ­¢
                                return skills

                        # æå–æŠ€èƒ½
                        cell_skills = self._extract_skills_from_merged_cell(cell_str)
                        if cell_skills:
                            skills.extend(cell_skills)
                            processed_cells.add(cell_key)
                            print(
                                f"      [{row},{col}] æå–åˆ°æŠ€èƒ½: {', '.join(cell_skills[:5])}"
                            )

                            # å¦‚æœæ˜¯åˆå¹¶å•å…ƒæ ¼ï¼Œæ ‡è®°ç›¸å…³å•å…ƒæ ¼ä¸ºå·²å¤„ç†
                            # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…å¯èƒ½éœ€è¦æ›´å¤æ‚çš„åˆå¹¶å•å…ƒæ ¼æ£€æµ‹
                            for r in range(row, min(row + 5, len(df))):
                                for c in range(
                                    max(0, col - 2), min(col + 3, len(df.columns))
                                ):
                                    try:
                                        if (
                                            pd.notna(df.iloc[r, c])
                                            and df.iloc[r, c] == cell
                                        ):
                                            processed_cells.add(f"{r},{c}")
                                    except:
                                        pass

        return skills

    def _extract_skills_from_merged_cell(self, cell_content: str) -> List[str]:
        """ä»åˆå¹¶å•å…ƒæ ¼ä¸­æå–æŠ€æœ¯å…³é”®å­—ï¼ˆå¤„ç†æ¢è¡Œå’Œã€åˆ†å‰²ï¼‰"""
        skills = []

        # æ¸…ç†å†…å®¹
        cell_content = cell_content.strip()

        # è·³è¿‡ç±»åˆ«æ ‡ç­¾
        category_labels = [
            "ï¼¯ï¼³",
            "OS",
            "ï¼¤ï¼¢",
            "DB",
            "è¨€èª",
            "é–‹ç™ºè¨€èª",
            "ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯",
            "ãƒ„ãƒ¼ãƒ«",
            "æŠ€è¡“çµŒé¨“",
            "ãã®ä»–",
            "é–‹ç™ºç’°å¢ƒ",
            "ã‚µãƒ¼ãƒãƒ¼",
            "IDE",
            "ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢",
            "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èª",
            "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹",
        ]
        if cell_content in category_labels:
            return []

        # åˆ†å‰²å†…å®¹ï¼ˆå¤„ç†å¤šç§åˆ†éš”ç¬¦ï¼‰
        # ä¼˜å…ˆæŒ‰æ¢è¡Œåˆ†å‰²ï¼Œç„¶åæŒ‰ã€åˆ†å‰²
        items = re.split(r"[\n\r]+", cell_content)

        for item in items:
            # å†æŒ‰ã€åˆ†å‰²
            sub_items = re.split(r"[ã€,ï¼Œ]", item)

            for sub_item in sub_items:
                sub_item = sub_item.strip()

                # ç§»é™¤å¯èƒ½çš„æ ‡è®°ç¬¦å·
                sub_item = re.sub(r"^[â—â—‹â–³Ã—â˜…â—â—¯â–²â€»]\s*", "", sub_item)

                if sub_item and self._is_valid_skill(sub_item):
                    normalized = self._normalize_skill_name(sub_item)
                    skills.append(normalized)

        return skills

    def _is_skill_section_end(self, cell_content: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åˆ°è¾¾æŠ€èƒ½åŒºåŸŸçš„ç»“æŸ"""
        end_markers = [
            "æ¥­å‹™å†…å®¹",
            "æ¥­å‹™å…§å®¹",
            "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ",
            "è·æ­´",
            "çµŒæ­´",
            "å®Ÿç¸¾",
            "æ‹…å½“æ¥­å‹™",
            "é–‹ç™ºå®Ÿç¸¾",
            "ä¸»ãªé–‹ç™º",
            "å‚ç”»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ",
            "ä½œæ¥­å†…å®¹",
            "æœŸé–“",
            "æ¡ˆä»¶",
            "æ¦‚è¦",
            "å·¥ç¨‹",
            "ã€",
            "â– ",
            "â—†",
            "â–¼",
            "â—ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ",
        ]

        cell_content = cell_content.strip()

        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç»“æŸæ ‡è®°
        for marker in end_markers:
            if marker in cell_content:
                return True

        # æ£€æŸ¥æ˜¯å¦æ˜¯æ—¥æœŸæ ¼å¼ï¼ˆé¡¹ç›®å¼€å§‹ï¼‰
        if re.match(r"^\d{4}[å¹´/]\d{1,2}[æœˆ/]", cell_content):
            return True

        # æ£€æŸ¥æ˜¯å¦åŒ…å«é¡¹ç›®å·¥ç¨‹ç›¸å…³è¯æ±‡
        if any(
            phase in cell_content
            for phase in ["è¦ä»¶å®šç¾©", "åŸºæœ¬è¨­è¨ˆ", "è©³ç´°è¨­è¨ˆ", "è£½é€ ", "è©¦é¨“", "ãƒ†ã‚¹ãƒˆ"]
        ):
            # ä½†å¦‚æœè¿™äº›è¯æ±‡åœ¨æŠ€èƒ½ä¸Šä¸‹æ–‡ä¸­ï¼ˆæ¯”å¦‚"åŸºæœ¬è¨­è¨ˆã‚¹ã‚­ãƒ«"ï¼‰ï¼Œåˆ™ä¸æ˜¯ç»“æŸ
            if not any(
                skill_context in cell_content
                for skill_context in ["ã‚¹ã‚­ãƒ«", "æŠ€è¡“", "çµŒé¨“"]
            ):
                return True

        return False

    def _extract_skills_fallback(self, df: pd.DataFrame) -> List[str]:
        """å¤‡ç”¨æŠ€èƒ½æå–æ–¹æ³•ï¼ˆå½“æ— æ³•æ‰¾åˆ°æ ‡å‡†æ ¼å¼æ—¶ï¼‰"""
        skills = []

        print(f"    ä½¿ç”¨å¤‡ç”¨æŠ€èƒ½æå–æ–¹æ³•")

        # æ–¹æ³•1: æŸ¥æ‰¾æŠ€èƒ½æ ‡è®°ç¬¦å·
        for idx in range(len(df)):
            for col in range(len(df.columns)):
                cell = df.iloc[idx, col]
                if self._is_skill_mark(cell):
                    # æ£€æŸ¥å‘¨å›´çš„å•å…ƒæ ¼
                    for r_off in range(-2, 3):
                        for c_off in range(-5, 1):
                            r = idx + r_off
                            c = col + c_off
                            if 0 <= r < len(df) and 0 <= c < len(df.columns):
                                skill_cell = df.iloc[r, c]
                                if pd.notna(skill_cell):
                                    cell_skills = self._extract_skills_from_merged_cell(
                                        str(skill_cell)
                                    )
                                    skills.extend(cell_skills)

        # æ–¹æ³•2: å…¨æ–‡æœç´¢å·²çŸ¥æŠ€èƒ½
        text = self._dataframe_to_text(df)
        for skill in self.valid_skills:
            # ä½¿ç”¨æ›´ä¸¥æ ¼çš„è¾¹ç•ŒåŒ¹é…ï¼Œé¿å…è¯¯åŒ¹é…
            pattern = rf"(?:^|\s|[ã€,ï¼Œ]){re.escape(skill)}(?:$|\s|[ã€,ï¼Œ])"
            if re.search(pattern, text, re.IGNORECASE):
                skills.append(skill)

        return skills

    def _process_and_deduplicate_skills(self, skills: List[str]) -> List[str]:
        """å¤„ç†å’Œå»é‡æŠ€èƒ½åˆ—è¡¨"""
        final_skills = []
        seen = set()
        seen_lower = set()

        for skill in skills:
            skill = skill.strip()
            if not skill:
                continue

            # æ ‡å‡†åŒ–
            normalized = self._normalize_skill_name(skill)
            normalized_lower = normalized.lower()

            # å»é‡ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰
            if normalized_lower not in seen_lower:
                seen_lower.add(normalized_lower)
                final_skills.append(normalized)

        # æŒ‰ä¼˜å…ˆçº§æ’åº
        def skill_priority(skill):
            programming_langs = [
                "Java",
                "Python",
                "JavaScript",
                "TypeScript",
                "C",
                "C++",
                "C#",
                "PHP",
                "Ruby",
                "Go",
                "Kotlin",
                "Swift",
                "Scala",
                "Rust",
                "VB.NET",
                "VB",
                "COBOL",
            ]
            frameworks = [
                "Spring",
                "SpringBoot",
                "React",
                "Vue",
                "Angular",
                "Django",
                "Flask",
                ".NET",
                "Rails",
                "Laravel",
                "Express",
            ]
            databases = [
                "MySQL",
                "PostgreSQL",
                "Oracle",
                "SQL Server",
                "MongoDB",
                "Redis",
                "DB2",
                "SQLite",
                "Access",
            ]
            cloud_platforms = ["AWS", "Azure", "GCP"]

            if skill in programming_langs:
                return (0, programming_langs.index(skill))
            elif skill in frameworks:
                return (1, frameworks.index(skill))
            elif skill in databases:
                return (2, databases.index(skill))
            elif skill in cloud_platforms:
                return (3, cloud_platforms.index(skill))
            else:
                return (4, skill)

        final_skills.sort(key=skill_priority)

        print(f"    æœ€ç»ˆæå–æŠ€èƒ½æ•°é‡: {len(final_skills)}")
        return final_skills

    def _convert_excel_serial_to_date(
        self, serial_number: Union[int, float]
    ) -> Optional[datetime]:
        """å°†Excelåºåˆ—æ•°å­—è½¬æ¢ä¸ºæ—¥æœŸ"""
        try:
            # Excelçš„åºåˆ—æ—¥æœŸï¼šä»1900å¹´1æœˆ1æ—¥å¼€å§‹çš„å¤©æ•°
            # æ³¨æ„ï¼šExcelé”™è¯¯åœ°è®¤ä¸º1900å¹´æ˜¯é—°å¹´ï¼Œæ‰€ä»¥éœ€è¦è°ƒæ•´
            if serial_number < 1:
                return None

            # Excelçš„bugï¼š1900å¹´è¢«é”™è¯¯åœ°è®¤ä¸ºæ˜¯é—°å¹´ï¼Œæ‰€ä»¥1900å¹´3æœˆ1æ—¥ä¹‹åéœ€è¦å‡å»1å¤©
            if serial_number >= 61:  # 1900å¹´3æœˆ1æ—¥å¯¹åº”61
                serial_number -= 1

            base_date = datetime(1900, 1, 1)
            result_date = base_date + timedelta(days=serial_number - 1)

            # éªŒè¯æ—¥æœŸæ˜¯å¦åˆç†
            if 1950 <= result_date.year <= 2030:
                return result_date

        except Exception as e:
            pass
        return None

    def _extract_age_final_fix(self, all_data: List[Dict]) -> str:
        """æœ€ç»ˆä¿®å¤ç‰ˆå¹´é¾„æå–"""
        candidates = []

        for data in all_data:
            df = data["df"]

            print(f"ğŸ” å¼€å§‹æœ€ç»ˆä¿®å¤ç‰ˆå¹´é¾„æå–...")

            # æ–¹æ³•1: æ‰«ææ‰€æœ‰Dateå¯¹è±¡
            for idx in range(min(30, len(df))):
                for col in range(len(df.columns)):
                    cell = df.iloc[idx, col]
                    if isinstance(cell, datetime):
                        if 1950 <= cell.year <= 2010:
                            age = self._calculate_age_from_birthdate(cell)
                            if age:
                                context_score = self._get_personal_info_context_score(
                                    df, idx, col
                                )
                                confidence = 2.0 + context_score * 0.5
                                candidates.append((str(age), confidence))
                                print(
                                    f"    Dateå¯¹è±¡å¹´é¾„å€™é€‰: [{idx},{col}] {cell} -> å¹´é¾„ {age}"
                                )

            # æ–¹æ³•2: **å…³é”®ä¿®å¤** - æ‰«æExcelåºåˆ—æ—¥æœŸæ•°å­—
            for idx in range(min(30, len(df))):
                for col in range(len(df.columns)):
                    cell = df.iloc[idx, col]
                    if pd.notna(cell) and isinstance(cell, (int, float)):
                        # æ£€æŸ¥æ˜¯å¦å¯èƒ½æ˜¯Excelåºåˆ—æ—¥æœŸï¼ˆèŒƒå›´å¤§æ¦‚åœ¨18000-50000ä¹‹é—´ï¼‰
                        if 18000 <= cell <= 50000:
                            converted_date = self._convert_excel_serial_to_date(cell)
                            if converted_date:
                                age = self._calculate_age_from_birthdate(converted_date)
                                if age:
                                    # æ£€æŸ¥å‘¨å›´æ˜¯å¦æœ‰ç”Ÿå¹´æœˆæ—¥ç›¸å…³æ ‡ç­¾
                                    has_age_context = False
                                    for r_off in range(-2, 3):
                                        for c_off in range(-5, 5):
                                            r = idx + r_off
                                            c = col + c_off
                                            if 0 <= r < len(df) and 0 <= c < len(
                                                df.columns
                                            ):
                                                context_cell = df.iloc[r, c]
                                                if pd.notna(context_cell):
                                                    context_str = str(context_cell)
                                                    if any(
                                                        k in context_str
                                                        for k in [
                                                            "ç”Ÿå¹´æœˆ",
                                                            "å¹´é½¢",
                                                            "æ­³",
                                                            "æ‰",
                                                        ]
                                                    ):
                                                        has_age_context = True
                                                        break
                                        if has_age_context:
                                            break

                                    if has_age_context:
                                        confidence = 3.0  # åºåˆ—æ—¥æœŸ+ä¸Šä¸‹æ–‡çš„é«˜ç½®ä¿¡åº¦
                                        candidates.append((str(age), confidence))
                                        print(
                                            f"    Excelåºåˆ—æ—¥æœŸå¹´é¾„å€™é€‰: [{idx},{col}] {cell} -> {converted_date} -> å¹´é¾„ {age}"
                                        )

            # æ–¹æ³•3: ä¼ ç»Ÿçš„å¹´é¾„æ ‡ç­¾æœç´¢
            for idx in range(min(30, len(df))):
                for col in range(len(df.columns)):
                    cell = df.iloc[idx, col]
                    if pd.notna(cell):
                        cell_str = str(cell)
                        if any(k in cell_str for k in self.keywords["age"]):
                            # æœç´¢é™„è¿‘çš„å¹´é¾„å€¼
                            for r_offset in range(-2, 6):
                                for c_offset in range(-2, 10):
                                    r = idx + r_offset
                                    c = col + c_offset
                                    if 0 <= r < len(df) and 0 <= c < len(df.columns):
                                        value = df.iloc[r, c]
                                        if pd.notna(value):
                                            if isinstance(value, datetime):
                                                age = (
                                                    self._calculate_age_from_birthdate(
                                                        value
                                                    )
                                                )
                                                if age:
                                                    candidates.append((str(age), 2.5))
                                            else:
                                                age = self._parse_age_value_improved(
                                                    str(value)
                                                )
                                                if age:
                                                    candidates.append((age, 2.0))

        if candidates:
            print(f"    å¹´é¾„å€™é€‰æ€»æ•°: {len(candidates)}")
            for age, conf in candidates:
                print(f"      å€™é€‰: å¹´é¾„={age}, ç½®ä¿¡åº¦={conf}")

            age_scores = defaultdict(float)
            for age, conf in candidates:
                age_scores[age] += conf
            best_age = max(age_scores.items(), key=lambda x: x[1])
            print(f"    æœ€ç»ˆé€‰æ‹©: å¹´é¾„={best_age[0]}, æ€»ç½®ä¿¡åº¦={best_age[1]}")
            return best_age[0]

        print(f"    æœªæ‰¾åˆ°å¹´é¾„ä¿¡æ¯")
        return ""

    def _extract_arrival_year_final_fix(self, all_data: List[Dict]) -> Optional[str]:
        """æœ€ç»ˆä¿®å¤ç‰ˆæ¥æ—¥å¹´ä»½æå–"""
        candidates = []

        for data in all_data:
            df = data["df"]

            print(f"ğŸ” å¼€å§‹æœ€ç»ˆä¿®å¤ç‰ˆæ¥æ—¥å¹´ä»½æå–...")

            # æ–¹æ³•1: æ‰«ææ‰€æœ‰Dateå¯¹è±¡
            for idx in range(min(30, len(df))):
                for col in range(len(df.columns)):
                    cell = df.iloc[idx, col]
                    if isinstance(cell, datetime):
                        if 1990 <= cell.year <= 2024:
                            # æ£€æŸ¥æ˜¯å¦æœ‰æ¥æ—¥ä¸Šä¸‹æ–‡
                            has_arrival_context = False
                            has_age_context = False
                            for r_off in range(-2, 3):
                                for c_off in range(-5, 5):
                                    r = idx + r_off
                                    c = col + c_off
                                    if 0 <= r < len(df) and 0 <= c < len(df.columns):
                                        context_cell = df.iloc[r, c]
                                        if pd.notna(context_cell):
                                            context_str = str(context_cell)
                                            if any(
                                                k in context_str
                                                for k in self.keywords["arrival"]
                                            ):
                                                has_arrival_context = True
                                            elif any(
                                                k in context_str
                                                for k in ["ç”Ÿå¹´æœˆ", "å¹´é½¢", "æ­³", "æ‰"]
                                            ):
                                                has_age_context = True
                                if has_arrival_context:
                                    break

                            if has_arrival_context:
                                # å¦‚æœä¹Ÿæœ‰å¹´é¾„ä¸Šä¸‹æ–‡ï¼Œå¯èƒ½æ˜¯ç”Ÿå¹´æœˆæ—¥ï¼Œé™ä½ç½®ä¿¡åº¦
                                confidence = 1.5 if has_age_context else 2.5
                                candidates.append((str(cell.year), confidence))
                                print(
                                    f"    Dateå¯¹è±¡æ¥æ—¥å€™é€‰: [{idx},{col}] {cell} -> å¹´ä»½ {cell.year} (ç½®ä¿¡åº¦: {confidence})"
                                )

            # æ–¹æ³•2: **å…³é”®ä¿®å¤** - æ‰«æExcelåºåˆ—æ—¥æœŸæ•°å­—
            for idx in range(min(30, len(df))):
                for col in range(len(df.columns)):
                    cell = df.iloc[idx, col]
                    if pd.notna(cell) and isinstance(cell, (int, float)):
                        # æ£€æŸ¥æ˜¯å¦å¯èƒ½æ˜¯Excelåºåˆ—æ—¥æœŸ
                        if 30000 <= cell <= 50000:  # å¤§æ¦‚1982-2037å¹´çš„èŒƒå›´
                            converted_date = self._convert_excel_serial_to_date(cell)
                            if converted_date and 1990 <= converted_date.year <= 2024:
                                # æ£€æŸ¥å‘¨å›´æ˜¯å¦æœ‰æ¥æ—¥ç›¸å…³æ ‡ç­¾
                                has_arrival_context = False
                                for r_off in range(-2, 3):
                                    for c_off in range(-5, 5):
                                        r = idx + r_off
                                        c = col + c_off
                                        if 0 <= r < len(df) and 0 <= c < len(
                                            df.columns
                                        ):
                                            context_cell = df.iloc[r, c]
                                            if pd.notna(context_cell):
                                                context_str = str(context_cell)
                                                if any(
                                                    k in context_str
                                                    for k in self.keywords["arrival"]
                                                ):
                                                    has_arrival_context = True
                                                    break
                                        if has_arrival_context:
                                            break
                                    if has_arrival_context:
                                        break

                                if has_arrival_context:
                                    confidence = 3.0  # åºåˆ—æ—¥æœŸ+ä¸Šä¸‹æ–‡çš„é«˜ç½®ä¿¡åº¦
                                    candidates.append(
                                        (str(converted_date.year), confidence)
                                    )
                                    print(
                                        f"    Excelåºåˆ—æ—¥æœŸæ¥æ—¥å€™é€‰: [{idx},{col}] {cell} -> {converted_date} -> å¹´ä»½ {converted_date.year}"
                                    )

            # æ–¹æ³•3: ä¼ ç»Ÿçš„æ¥æ—¥å…³é”®è¯æœç´¢
            for idx in range(min(40, len(df))):
                for col in range(len(df.columns)):
                    cell = df.iloc[idx, col]
                    if pd.notna(cell):
                        cell_str = str(cell)
                        if any(k in cell_str for k in self.keywords["arrival"]):
                            # æœç´¢é™„è¿‘çš„å¹´ä»½
                            for r_off in range(-2, 5):
                                for c_off in range(-2, 25):
                                    r = idx + r_off
                                    c = col + c_off
                                    if 0 <= r < len(df) and 0 <= c < len(df.columns):
                                        value = df.iloc[r, c]
                                        if pd.notna(value):
                                            if isinstance(value, datetime):
                                                if 1990 <= value.year <= 2024:
                                                    candidates.append(
                                                        (str(value.year), 2.0)
                                                    )
                                            else:
                                                year = self._parse_year_value_improved(
                                                    str(value)
                                                )
                                                if year:
                                                    candidates.append((year, 1.8))

        if candidates:
            print(f"    æ¥æ—¥å¹´ä»½å€™é€‰æ€»æ•°: {len(candidates)}")
            for year, conf in candidates:
                print(f"      å€™é€‰: å¹´ä»½={year}, ç½®ä¿¡åº¦={conf}")

            year_scores = defaultdict(float)
            for year, conf in candidates:
                year_scores[year] += conf
            if year_scores:
                best_year = max(year_scores.items(), key=lambda x: x[1])
                print(f"    æœ€ç»ˆé€‰æ‹©: å¹´ä»½={best_year[0]}, æ€»ç½®ä¿¡åº¦={best_year[1]}")
                return best_year[0]

        print(f"    æœªæ‰¾åˆ°æ¥æ—¥å¹´ä»½ä¿¡æ¯")
        return None

    def _extract_nationality_final_fix(self, all_data: List[Dict]) -> Optional[str]:
        """æœ€ç»ˆä¿®å¤ç‰ˆå›½ç±æå–"""
        valid_nationalities = [
            "ä¸­å›½",
            "æ—¥æœ¬",
            "éŸ“å›½",
            "ãƒ™ãƒˆãƒŠãƒ ",
            "ãƒ•ã‚£ãƒªãƒ”ãƒ³",
            "ã‚¤ãƒ³ãƒ‰",
            "ãƒãƒ‘ãƒ¼ãƒ«",
            "ã‚¢ãƒ¡ãƒªã‚«",
            "ãƒ–ãƒ©ã‚¸ãƒ«",
            "å°æ¹¾",
            "ã‚¿ã‚¤",
            "ã‚¤ãƒ³ãƒ‰ãƒã‚·ã‚¢",
            "ãƒãƒ³ã‚°ãƒ©ãƒ‡ã‚·ãƒ¥",
            "ã‚¹ãƒªãƒ©ãƒ³ã‚«",
            "ãƒŸãƒ£ãƒ³ãƒãƒ¼",
            "ã‚«ãƒ³ãƒœã‚¸ã‚¢",
            "ãƒ©ã‚ªã‚¹",
            "ãƒ¢ãƒ³ã‚´ãƒ«",
        ]

        candidates = []

        for data in all_data:
            df = data["df"]

            print(f"ğŸ” å¼€å§‹æœ€ç»ˆä¿®å¤ç‰ˆå›½ç±æå–...")

            # æ–¹æ³•1: æ‰«ææ•´ä¸ªè¡¨æ ¼çš„æ‰€æœ‰å›½ç±å…³é”®è¯
            for idx in range(min(50, len(df))):
                for col in range(len(df.columns)):
                    cell = df.iloc[idx, col]
                    if pd.notna(cell):
                        cell_str = str(cell).strip()

                        # ç›´æ¥æ£€æŸ¥æ˜¯å¦æ˜¯å›½ç±å€¼
                        if cell_str in valid_nationalities:
                            print(f"    å‘ç°å›½ç±å€™é€‰: [{idx},{col}] {cell_str}")

                            # è®¡ç®—ä¸Šä¸‹æ–‡è¯„åˆ†
                            context_score = 0

                            # æ£€æŸ¥åŒè¡Œæ˜¯å¦æœ‰ä¸ªäººä¿¡æ¯
                            row_data = df.iloc[idx]
                            row_text = " ".join(
                                [str(cell) for cell in row_data if pd.notna(cell)]
                            )
                            if any(
                                keyword in row_text
                                for keyword in [
                                    "æ°å",
                                    "æ€§åˆ¥",
                                    "å¹´é½¢",
                                    "æœ€å¯„",
                                    "ä½æ‰€",
                                    "ç”·",
                                    "å¥³",
                                ]
                            ):
                                context_score += 2.0
                                print(f"      åŒè¡Œæœ‰ä¸ªäººä¿¡æ¯")

                            # æ£€æŸ¥å‘¨å›´æ˜¯å¦æœ‰ä¸ªäººä¿¡æ¯
                            for r_off in range(-3, 4):
                                for c_off in range(-5, 6):
                                    r = idx + r_off
                                    c = col + c_off
                                    if 0 <= r < len(df) and 0 <= c < len(df.columns):
                                        nearby_cell = df.iloc[r, c]
                                        if pd.notna(nearby_cell):
                                            nearby_text = str(nearby_cell)
                                            if any(
                                                keyword in nearby_text
                                                for keyword in [
                                                    "æ°å",
                                                    "æ€§åˆ¥",
                                                    "å¹´é½¢",
                                                    "å­¦æ­´",
                                                ]
                                            ):
                                                context_score += 1.0

                            total_confidence = max(1.0, context_score)
                            candidates.append((cell_str, total_confidence))

            # æ–¹æ³•2: æŸ¥æ‰¾å›½ç±æ ‡ç­¾é™„è¿‘çš„å€¼
            for idx in range(min(40, len(df))):
                for col in range(len(df.columns)):
                    cell = df.iloc[idx, col]
                    if pd.notna(cell) and any(
                        k in str(cell) for k in self.keywords["nationality"]
                    ):
                        print(f"    å‘ç°å›½ç±æ ‡ç­¾: [{idx},{col}] {cell}")
                        for r_off in range(-3, 6):
                            for c_off in range(-3, 15):
                                r = idx + r_off
                                c = col + c_off
                                if 0 <= r < len(df) and 0 <= c < len(df.columns):
                                    value = df.iloc[r, c]
                                    if pd.notna(value):
                                        value_str = str(value).strip()
                                        if value_str in valid_nationalities:
                                            confidence = 3.0
                                            print(f"      æ‰¾åˆ°å›½ç±å€¼: {value_str}")
                                            candidates.append((value_str, confidence))

        if candidates:
            print(f"    å›½ç±å€™é€‰æ€»æ•°: {len(candidates)}")
            for nationality, conf in candidates:
                print(f"      å€™é€‰: å›½ç±={nationality}, ç½®ä¿¡åº¦={conf}")

            nationality_scores = defaultdict(float)
            for nationality, conf in candidates:
                nationality_scores[nationality] += conf
            if nationality_scores:
                best_nationality = max(nationality_scores.items(), key=lambda x: x[1])
                print(
                    f"    æœ€ç»ˆé€‰æ‹©: å›½ç±={best_nationality[0]}, æ€»ç½®ä¿¡åº¦={best_nationality[1]}"
                )
                return best_nationality[0]

        print(f"    æœªæ‰¾åˆ°å›½ç±ä¿¡æ¯")
        return None

    def _extract_experience_final_fix(self, all_data: List[Dict]) -> str:
        """æœ€ç»ˆä¿®å¤ç‰ˆç»éªŒæå–"""
        candidates = []

        for data in all_data:
            df = data["df"]

            print(f"ğŸ” å¼€å§‹æœ€ç»ˆä¿®å¤ç‰ˆç»éªŒæå–...")

            # æ–¹æ³•1: æŸ¥æ‰¾ç»éªŒå…³é”®è¯
            for idx in range(min(60, len(df))):
                for col in range(len(df.columns)):
                    cell = df.iloc[idx, col]
                    if pd.notna(cell):
                        cell_str = str(cell)
                        if any(k in cell_str for k in self.keywords["experience"]):
                            print(f"    å‘ç°ç»éªŒå…³é”®è¯: [{idx},{col}] {cell_str}")

                            # æ’é™¤è¯´æ˜æ–‡å­—
                            if any(
                                ex in cell_str
                                for ex in [
                                    "ä»¥ä¸Š",
                                    "æœªæº€",
                                    "â—",
                                    "â—‹",
                                    "â–³",
                                    "æŒ‡å°",
                                    "ç²¾é€š",
                                    "ã§ãã‚‹",
                                ]
                            ):
                                print(f"      è·³è¿‡è¯´æ˜æ–‡å­—")
                                continue

                            # æœç´¢æ•°å€¼
                            for r_off in range(-3, 6):
                                for c_off in range(-3, 30):
                                    r = idx + r_off
                                    c = col + c_off
                                    if 0 <= r < len(df) and 0 <= c < len(df.columns):
                                        value = df.iloc[r, c]
                                        if pd.notna(value):
                                            exp = self._parse_experience_value(
                                                str(value)
                                            )
                                            if exp:
                                                confidence = 1.0
                                                print(
                                                    f"      æ‰¾åˆ°ç»éªŒå€¼: [{r},{c}] {value} -> {exp}"
                                                )

                                                # æ ¹æ®å…³é”®è¯ç±»å‹è°ƒæ•´ç½®ä¿¡åº¦
                                                if "ã‚½ãƒ•ãƒˆé–¢é€£æ¥­å‹™çµŒé¨“å¹´æ•°" in cell_str:
                                                    confidence *= 3.0
                                                elif "ITçµŒé¨“å¹´æ•°" in cell_str:
                                                    confidence *= 2.5
                                                elif "å®Ÿå‹™çµŒé¨“" in cell_str:
                                                    confidence *= 2.0

                                                candidates.append((exp, confidence))

            # æ–¹æ³•2: **GTæ–‡ä»¶ç‰¹æ®Šå¤„ç†** - æ¤œæŸ¥å®Ÿå‹™å¹´æ•°è¡¨æ ¼
            # å¯¹äºGTæ–‡ä»¶ï¼Œå®Ÿå‹™å¹´æ•°å¯èƒ½æ²¡æœ‰å…·ä½“æ•°å­—ï¼Œè€Œæ˜¯ç”¨ç¬¦å·è¡¨ç¤º
            print(f"    æ£€æŸ¥å®Ÿå‹™å¹´æ•°è¡¨æ ¼æ ¼å¼...")

            # åœ¨GTæ–‡ä»¶ä¸­ï¼ŒçµŒé¨“å¯èƒ½ä»¥å…¶ä»–å½¢å¼å­˜åœ¨ï¼Œæ¯”å¦‚é¡¹ç›®å¼€å§‹æ—¶é—´æ¨ç®—
            for idx in range(min(50, len(df))):
                for col in range(len(df.columns)):
                    cell = df.iloc[idx, col]
                    if isinstance(cell, datetime):
                        # æ£€æŸ¥æ˜¯å¦æ˜¯é¡¹ç›®å¼€å§‹æ—¥æœŸï¼ˆå¯ä»¥æ¨ç®—ç»éªŒï¼‰
                        if 2015 <= cell.year <= 2024:
                            # æ£€æŸ¥åŒè¡Œæ˜¯å¦æœ‰é¡¹ç›®æè¿°
                            row_data = df.iloc[idx]
                            row_text = " ".join(
                                [str(cell) for cell in row_data if pd.notna(cell)]
                            )
                            if any(
                                keyword in row_text
                                for keyword in [
                                    "ã‚·ã‚¹ãƒ†ãƒ ",
                                    "é–‹ç™º",
                                    "æ¥­å‹™",
                                    "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ",
                                ]
                            ):
                                # ä»æœ€æ—©çš„é¡¹ç›®æ—¥æœŸæ¨ç®—ç»éªŒå¹´æ•°
                                experience_years = 2024 - cell.year
                                if 1 <= experience_years <= 15:
                                    # å¯¹äºåˆç†çš„é¡¹ç›®ç»éªŒï¼Œç»™äºˆæ›´é«˜ç½®ä¿¡åº¦
                                    confidence = 1.5 if experience_years >= 5 else 1.2
                                    exp_str = f"{experience_years}å¹´"
                                    candidates.append((exp_str, confidence))
                                    print(
                                        f"      ä»é¡¹ç›®æ—¥æœŸæ¨ç®—ç»éªŒ: {cell} -> {exp_str} (ç½®ä¿¡åº¦: {confidence})"
                                    )

        if candidates:
            print(f"    ç»éªŒå€™é€‰æ€»æ•°: {len(candidates)}")
            for exp, conf in candidates:
                print(f"      å€™é€‰: ç»éªŒ={exp}, ç½®ä¿¡åº¦={conf}")

            candidates.sort(key=lambda x: x[1], reverse=True)
            result = candidates[0][0].translate(self.trans_table)
            print(f"    æœ€ç»ˆé€‰æ‹©: ç»éªŒ={result}, ç½®ä¿¡åº¦={candidates[0][1]}")
            return result

        print(f"    æœªæ‰¾åˆ°ç»éªŒä¿¡æ¯")
        return ""

    def _calculate_age_from_birthdate(self, birthdate: datetime) -> Optional[int]:
        """ä»ç”Ÿå¹´æœˆæ—¥è®¡ç®—å¹´é¾„"""
        try:
            current_date = datetime(2024, 11, 1)
            age = current_date.year - birthdate.year
            if (current_date.month, current_date.day) < (
                birthdate.month,
                birthdate.day,
            ):
                age -= 1
            if 15 <= age <= 75:
                return age
        except:
            pass
        return None

    def _parse_age_value_improved(self, value: str) -> Optional[str]:
        """æ”¹è¿›çš„å¹´é¾„å€¼è§£æ"""
        value = str(value).strip()
        if len(value) > 15 or "å¹´æœˆ" in value or "è¥¿æš¦" in value or "19" in value:
            return None

        # å¤„ç†"æº€"å­—æ ¼å¼
        match = re.search(r"æº€\s*(\d{1,2})\s*[æ­³æ‰]", value)
        if match:
            age = int(match.group(1))
            if 18 <= age <= 65:
                return str(age)

        # ä¼˜å…ˆåŒ¹é…åŒ…å«"æ­³"æˆ–"æ‰"çš„
        match = re.search(r"(\d{1,2})\s*[æ­³æ‰]", value)
        if match:
            age = int(match.group(1))
            if 18 <= age <= 65:
                return str(age)

        # å°è¯•æå–çº¯æ•°å­—
        match = re.search(r"^(\d{1,2})$", value)
        if match:
            age = int(match.group(1))
            if 18 <= age <= 65:
                return str(age)

        return None

    def _parse_year_value_improved(self, value: str) -> Optional[str]:
        """æ”¹è¿›çš„å¹´ä»½å€¼è§£æ"""
        value_str = str(value).strip()

        # ç›´æ¥çš„å¹´ä»½æ ¼å¼
        if re.match(r"^20\d{2}$", value_str):
            return value_str

        # å¹´æœˆæ ¼å¼
        match = re.search(r"(20\d{2})[å¹´/æœˆ]", value_str)
        if match:
            return match.group(1)

        # 2016å¹´4æœˆæ ¼å¼
        match = re.search(r"(20\d{2})å¹´\d+æœˆ", value_str)
        if match:
            return match.group(1)

        # å’Œæš¦
        if "å¹³æˆ" in value_str:
            match = re.search(r"å¹³æˆ\s*(\d+)", value_str)
            if match:
                return str(1988 + int(match.group(1)))
        elif "ä»¤å’Œ" in value_str:
            match = re.search(r"ä»¤å’Œ\s*(\d+)", value_str)
            if match:
                return str(2018 + int(match.group(1)))

        return None

    def _get_personal_info_context_score(
        self, df: pd.DataFrame, row: int, col: int
    ) -> float:
        """è·å–ä¸ªäººä¿¡æ¯ä¸Šä¸‹æ–‡è¯„åˆ†"""
        score = 0.0
        personal_keywords = (
            self.keywords["name"]
            + self.keywords["gender"]
            + self.keywords["age"]
            + ["å­¦æ­´", "æœ€çµ‚å­¦æ­´", "ä½æ‰€", "æœ€å¯„é§…", "æœ€å¯„", "çµŒé¨“", "å®Ÿå‹™"]
        )

        for r in range(max(0, row - 3), min(len(df), row + 4)):
            for c in range(max(0, col - 5), min(len(df.columns), col + 6)):
                cell = df.iloc[r, c]
                if pd.notna(cell):
                    cell_str = str(cell)
                    for keyword in personal_keywords:
                        if keyword in cell_str:
                            score += 1.0

        return score

    # ä¿ç•™åŸæœ‰çš„å…¶ä»–æ–¹æ³•
    def _extract_name(self, all_data: List[Dict]) -> str:
        """æå–å§“å"""
        candidates = []

        for data in all_data:
            df = data["df"]

            for idx in range(min(20, len(df))):
                for col in range(len(df.columns)):
                    cell = df.iloc[idx, col]
                    if pd.notna(cell) and any(
                        k in str(cell) for k in self.keywords["name"]
                    ):
                        for r_offset in range(-2, 5):
                            for c_offset in range(-2, 15):
                                r = idx + r_offset
                                c = col + c_offset
                                if 0 <= r < len(df) and 0 <= c < len(df.columns):
                                    value = df.iloc[r, c]
                                    if pd.notna(value) and self._is_valid_name(
                                        str(value)
                                    ):
                                        confidence = 1.0
                                        if r == idx:
                                            confidence *= 1.5
                                        if c > col and c - col <= 5:
                                            confidence *= 1.3
                                        candidates.append(
                                            (str(value).strip(), confidence)
                                        )

        if candidates:
            candidates.sort(key=lambda x: x[1], reverse=True)
            return candidates[0][0]
        return ""

    def _extract_gender(self, all_data: List[Dict]) -> Optional[str]:
        """æå–æ€§åˆ«"""
        for data in all_data:
            df = data["df"]

            for idx in range(min(30, len(df))):
                for col in range(len(df.columns)):
                    cell = df.iloc[idx, col]
                    if pd.notna(cell):
                        cell_str = str(cell).strip()

                        if cell_str in ["ç”·", "ç”·æ€§"]:
                            if self._has_nearby_keyword(
                                df, idx, col, self.keywords["gender"], radius=5
                            ):
                                return "ç”·æ€§"
                        elif cell_str in ["å¥³", "å¥³æ€§"]:
                            if self._has_nearby_keyword(
                                df, idx, col, self.keywords["gender"], radius=5
                            ):
                                return "å¥³æ€§"
                        elif any(k in cell_str for k in self.keywords["gender"]):
                            for r_off in range(-2, 3):
                                for c_off in range(-2, 10):
                                    r = idx + r_off
                                    c = col + c_off
                                    if 0 <= r < len(df) and 0 <= c < len(df.columns):
                                        value = df.iloc[r, c]
                                        if pd.notna(value):
                                            v_str = str(value).strip()
                                            if v_str in ["ç”·", "ç”·æ€§", "M", "Male"]:
                                                return "ç”·æ€§"
                                            elif v_str in ["å¥³", "å¥³æ€§", "F", "Female"]:
                                                return "å¥³æ€§"
        return None

    def _extract_japanese_level(self, all_data: List[Dict]) -> str:
        """æå–æ—¥è¯­æ°´å¹³"""
        candidates = []

        for data in all_data:
            text = data["text"]
            df = data["df"]

            jlpt_patterns = [
                (r"JLPT\s*[Nnï¼®]([1-5ï¼‘-ï¼•])", 2.0),
                (r"[Nnï¼®]([1-5ï¼‘-ï¼•])\s*(?:åˆæ ¼|å–å¾—|ãƒ¬ãƒ™ãƒ«|ç´š)", 1.8),
                (r"æ—¥æœ¬èªèƒ½åŠ›è©¦é¨“\s*[Nnï¼®]?([1-5ï¼‘-ï¼•])\s*ç´š?", 1.5),
                (r"(?:^|\s)[Nnï¼®]([1-5ï¼‘-ï¼•])(?:\s|$|[\(ï¼ˆ])", 1.0),
                (r"æ—¥æœ¬èª.*?([ä¸€äºŒä¸‰å››äº”])ç´š", 1.3),
                (r"([ä¸€äºŒä¸‰å››äº”])ç´š.*?æ—¥æœ¬èª", 1.3),
            ]

            for pattern, confidence in jlpt_patterns:
                matches = re.finditer(pattern, text, re.IGNORECASE | re.MULTILINE)
                for match in matches:
                    level_str = match.group(1)
                    kanji_to_num = {
                        "ä¸€": "1",
                        "äºŒ": "2",
                        "ä¸‰": "3",
                        "å››": "4",
                        "äº”": "5",
                    }
                    if level_str in kanji_to_num:
                        level_num = kanji_to_num[level_str]
                    else:
                        level_num = level_str.translate(self.trans_table)
                    level = f"N{level_num}"
                    candidates.append((level, confidence))

            if "ãƒ“ã‚¸ãƒã‚¹" in text and any(jp in text for jp in ["æ—¥æœ¬èª", "æ—¥èª"]):
                candidates.append(("ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒ™ãƒ«", 0.8))
            elif "ä¸Šç´š" in text and any(jp in text for jp in ["æ—¥æœ¬èª", "æ—¥èª"]):
                candidates.append(("ä¸Šç´š", 0.8))
            elif "ä¸­ç´š" in text and any(jp in text for jp in ["æ—¥æœ¬èª", "æ—¥èª"]):
                candidates.append(("ä¸­ç´š", 0.7))

        if candidates:
            candidates.sort(key=lambda x: x[1], reverse=True)
            return candidates[0][0]
        return ""

    # æŠ€èƒ½ç›¸å…³çš„è¾…åŠ©æ–¹æ³•
    def _is_skill_mark(self, value) -> bool:
        if pd.isna(value):
            return False
        value_str = str(value).strip()
        return value_str in self.skill_marks

    def _is_valid_skill(self, skill: str) -> bool:
        if not skill or not isinstance(skill, str):
            return False
        skill = skill.strip()
        if len(skill) < 1 or len(skill) > 50:
            return False
        for pattern in self.exclude_patterns:
            if re.match(pattern, skill, re.IGNORECASE):
                return False
        if skill.isdigit():
            return False
        if re.search(r"\d{4}[-/]\d{2}[-/]\d{2}", skill):
            return False
        if skill == "C":
            return True
        if len(skill) == 1 and skill not in self.skill_marks:
            return False
        normalized = self._normalize_skill_name(skill)
        if normalized in self.valid_skills:
            return True
        skill_lower = skill.lower()
        for valid_skill in self.valid_skills:
            if valid_skill.lower() == skill_lower:
                return True
        if re.search(r"[a-zA-Z]", skill) and len(skill) <= 30:
            exclude_words = [
                "è¨­è¨ˆ",
                "è£½é€ ",
                "è©¦é¨“",
                "ãƒ†ã‚¹ãƒˆ",
                "ç®¡ç†",
                "çµŒé¨“",
                "æ‹…å½“",
                "å¹´",
                "æœˆ",
            ]
            if not any(word in skill for word in exclude_words):
                return True
        os_names = ["Windows", "Linux", "Unix", "Solaris", "Ubuntu", "CentOS", "RedHat"]
        if any(os.lower() in skill_lower for os in os_names):
            return True
        return False

    def _normalize_skill_name(self, skill: str) -> str:
        skill = skill.strip()
        skill_mapping = {
            "JAVA": "Java",
            "java": "Java",
            "Javascript": "JavaScript",
            "javascript": "JavaScript",
            "MySql": "MySQL",
            "mysql": "MySQL",
            "Intellij": "IntelliJ",
            "intellij": "IntelliJ",
            "Junit": "JUnit",
            "junit": "JUnit",
            "python": "Python",
            "React.js": "React",
            "Vue.js": "Vue",
            "Node.JS": "Node.js",
            "node.js": "Node.js",
            "LINUX": "Linux",
            "linux": "Linux",
            "UNIX": "Unix",
            "unix": "Unix",
            "ORACLE": "Oracle",
            "oracle": "Oracle",
            "eclipse": "Eclipse",
            "spring": "Spring",
            "springboot": "SpringBoot",
            "postman": "Postman",
            "git": "Git",
            "github": "GitHub",
            "struct2": "Struts2",
            "PG": "PostgreSQL",
            "JS": "JavaScript",
            "ï¼¯ï¼³": "OS",
            "ï¼¤ï¼¢": "DB",
            "Jquery": "jQuery",
            "jquery": "jQuery",
            "JBOSS": "JBoss",
            "jboss": "JBoss",
            "SqlServer": "SQL Server",
            "sqlserver": "SQL Server",
            "Form Desigener": "Form Designer",
            "win10": "Windows 10",
            "Win10": "Windows 10",
        }
        if skill in skill_mapping:
            return skill_mapping[skill]
        skill_lower = skill.lower()
        for k, v in skill_mapping.items():
            if k.lower() == skill_lower:
                return v
        skill = re.sub(r"\s+", " ", skill)
        if "ï¼¯ï¼³" in skill:
            skill = skill.replace("ï¼¯ï¼³", "OS")
        if "ï¼¤ï¼¢" in skill:
            skill = skill.replace("ï¼¤ï¼¢", "DB")
        if skill in self.valid_skills:
            return skill
        for valid_skill in self.valid_skills:
            if valid_skill.lower() == skill_lower:
                return valid_skill
        return skill

    def _is_valid_name(self, name: str) -> bool:
        name = str(name).strip()
        exclude_words = [
            "æ°å",
            "åå‰",
            "ãƒ•ãƒªã‚¬ãƒŠ",
            "æ€§åˆ¥",
            "å¹´é½¢",
            "å›½ç±",
            "ç”·",
            "å¥³",
            "æ­³",
            "æ‰",
            "çµŒé¨“",
            "è³‡æ ¼",
            "å­¦æ­´",
            "ä½æ‰€",
            "é›»è©±",
            "ãƒ¡ãƒ¼ãƒ«",
            "ç¾åœ¨",
            "ã‚¹ã‚­ãƒ«ã‚·ãƒ¼ãƒˆ",
            "å±¥æ­´æ›¸",
            "è·å‹™çµŒæ­´æ›¸",
            "æŠ€è¡“",
            "å¹´æœˆ",
            "ç”Ÿå¹´æœˆ",
        ]
        for word in exclude_words:
            if word in name:
                return False
        if len(name) < 2 or len(name) > 15:
            return False
        if name.replace(" ", "").replace("ã€€", "").isdigit():
            return False
        if not re.search(r"[ä¸€-é¾¥ã-ã‚“ã‚¡-ãƒ³a-zA-Z]", name):
            return False
        if re.match(r"^[A-Z]{2,4}$", name):
            return True
        if " " in name or "ã€€" in name:
            parts = re.split(r"[\sã€€]+", name)
            if len(parts) == 2 and all(len(p) >= 1 for p in parts):
                return True
        return True

    def _parse_experience_value(self, value: str) -> Optional[str]:
        value = str(value).strip()
        if any(exclude in value for exclude in ["ä»¥ä¸Š", "æœªæº€", "â—", "â—‹", "â–³", "çµŒé¨“"]):
            return None
        value = value.translate(self.trans_table)
        patterns = [
            (
                r"^(\d+)\s*å¹´\s*(\d+)\s*ãƒ¶æœˆ$",
                lambda m: f"{m.group(1)}å¹´{m.group(2)}ãƒ¶æœˆ",
            ),
            (
                r"^(\d+(?:\.\d+)?)\s*å¹´$",
                lambda m: (
                    f"{float(m.group(1)):.0f}å¹´"
                    if float(m.group(1)) == int(float(m.group(1)))
                    else f"{m.group(1)}å¹´"
                ),
            ),
            (
                r"^(\d+(?:\.\d+)?)\s*$",
                lambda m: (
                    f"{float(m.group(1)):.0f}å¹´"
                    if 1 <= float(m.group(1)) <= 40
                    else None
                ),
            ),
            (r"(\d+)\s*å¹´\s*(\d+)\s*ãƒ¶æœˆ", lambda m: f"{m.group(1)}å¹´{m.group(2)}ãƒ¶æœˆ"),
            (r"(\d+)\s*å¹´", lambda m: f"{m.group(1)}å¹´"),
        ]
        for pattern, formatter in patterns:
            match = re.search(pattern, value)
            if match:
                result = formatter(match)
                if result:
                    return result
        return None

    def _has_nearby_keyword(
        self, df: pd.DataFrame, row: int, col: int, keywords: List[str], radius: int = 5
    ) -> bool:
        for r in range(max(0, row - radius), min(len(df), row + radius + 1)):
            for c in range(
                max(0, col - radius), min(len(df.columns), col + radius + 1)
            ):
                cell = df.iloc[r, c]
                if pd.notna(cell) and any(k in str(cell) for k in keywords):
                    return True
        return False

    def _dataframe_to_text(self, df: pd.DataFrame) -> str:
        text_parts = []
        for idx, row in df.iterrows():
            row_text = " ".join([str(cell) for cell in row if pd.notna(cell)])
            if row_text.strip():
                text_parts.append(row_text)
        return "\n".join(text_parts)


# æµ‹è¯•å‡½æ•°
if __name__ == "__main__":
    extractor = FinalFixResumeExtractor()

    test_files = [
        "ã‚¹ã‚­ãƒ«ã‚·ãƒ¼ãƒˆ_ryu.xlsx",  # æµ‹è¯•Excelåºåˆ—æ—¥æœŸæ¥æ—¥å¹´ä»½
        "æ¥­å‹™çµŒæ­´æ›¸_ FYY_é‡‘ç”ºé§….xlsx",  # æµ‹è¯•Excelåºåˆ—æ—¥æœŸå¹´é¾„
        "ã‚¹ã‚­ãƒ«ã‚·ãƒ¼ãƒˆGT.xlsx",  # æµ‹è¯•å›½ç±å’Œç»éªŒ
    ]

    for file in test_files:
        print(f"\n{'='*60}")
        print(f"ğŸ”§ æœ€ç»ˆä¿®å¤æµ‹è¯•æ–‡ä»¶V1: {file}")
        print("=" * 60)

        try:
            result = extractor.extract_from_excel(file)

            if "error" not in result:
                print(f"âœ… å§“å: {result['name']}")
                print(f"âœ… æ€§åˆ«: {result['gender']}")
                print(f"âœ… å¹´é¾„: {result['age']}")
                print(f"âœ… å›½ç±: {result['nationality']}")
                print(f"âœ… æ¥æ—¥å¹´ä»½: {result['arrival_year_japan']}")
                print(f"âœ… ç»éªŒ: {result['experience']}")
                print(f"âœ… æ—¥è¯­: {result['japanese_level']}")
                print(
                    f"âœ… æŠ€èƒ½({len(result['skills'])}ä¸ª): {', '.join(result['skills'][:10])}"
                )
                if len(result["skills"]) > 10:
                    print(f"   ... è¿˜æœ‰ {len(result['skills']) - 10} ä¸ªæŠ€èƒ½")

                print("\nğŸ“‹ JSONæ ¼å¼:")
                print(json.dumps(result, ensure_ascii=False, indent=2))
            else:
                print(f"âŒ é”™è¯¯: {result['error']}")
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
            import traceback

            traceback.print_exc()
