# -*- coding: utf-8 -*-
"""æŠ€èƒ½æå–å™¨"""

from typing import List, Dict, Any, Tuple, Optional
import pandas as pd
import re

from base.base_extractor import BaseExtractor
from base.constants import VALID_SKILLS, SKILL_MARKS, EXCLUDE_PATTERNS


class SkillsExtractor(BaseExtractor):
    """æŠ€èƒ½ä¿¡æ¯æå–å™¨"""

    def __init__(self):
        super().__init__()
        # å·¥ç¨‹é˜¶æ®µå…³é”®è¯ï¼ˆç”¨äºå®šä½å³ä¾§åˆ—ï¼‰
        self.design_keywords = [
            "åŸºæœ¬è¨­è¨ˆ",
            "è©³ç´°è¨­è¨ˆ",
            "è£½é€ ",
            "å˜ä½“ãƒ†ã‚¹ãƒˆ",
            "çµåˆãƒ†ã‚¹ãƒˆ",
            "ç·åˆãƒ†ã‚¹ãƒˆ",
            "é‹ç”¨ä¿å®ˆ",
            "è¦ä»¶å®šç¾©",
            "åŸºæœ¬è®¾è®¡",
            "è¯¦ç»†è®¾è®¡",
            # "No.",  # æ·»åŠ  No. ä½œä¸ºå·¥ç¨‹é˜¶æ®µæ ‡é¢˜
        ]

        # æŠ€æœ¯åˆ—æ ‡é¢˜å…³é”®è¯ï¼ˆç”¨äºè¯†åˆ«æŠ€æœ¯åˆ—ï¼‰
        self.tech_column_keywords = [
            "è¨€èª",
            "ãƒ„ãƒ¼ãƒ«",
            "æŠ€è¡“",
            "ã‚¹ã‚­ãƒ«",
            "DB",
            "OS",
            "ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯",
            "é–‹ç™ºç’°å¢ƒ",
            "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°",
            "æ©Ÿç¨®",
            "Git",
            "SVN",
            "ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†",
        ]

        # ä¸åº”è¯¥è¢«ç©ºæ ¼åˆ†å‰²çš„æŠ€èƒ½ï¼ˆä¿æŒå®Œæ•´æ€§ï¼‰
        self.no_split_skills = {
            "VS Code",
            "Visual Studio",
            "Android Studio",
            "IntelliJ IDEA",
            "SQL Server",
            "Azure SQL Database",
            "Azure SQL DB",
            "React Native",
            "Node.js",
            "Vue.js",
            "React.js",
            "TeraTerm",
            "Tera Term",
            "Win95/98",
            "Finance and Operations",
            "Dynamics 365",
            "AWS Glue",
            "AWS S3",
            "AWS Lambda",
            "AWS EC2",
            "AWS IAM",
            "AWS CodeCommit",
        }

    def extract(self, all_data: List[Dict[str, Any]]) -> List[str]:
        """æå–æŠ€èƒ½åˆ—è¡¨

        Args:
            all_data: åŒ…å«æ‰€æœ‰sheetæ•°æ®çš„åˆ—è¡¨

        Returns:
            æŠ€èƒ½åˆ—è¡¨
        """
        all_skills = []

        for data in all_data:
            df = data["df"]
            sheet_name = data.get("sheet_name", "Unknown")

            print(f"\nğŸ” å¼€å§‹æŠ€æœ¯å…³é”®å­—æå– - Sheet: {sheet_name}")
            print(f"    è¡¨æ ¼å¤§å°: {df.shape[0]}è¡Œ x {df.shape[1]}åˆ—")

            # ä¸»è¦æ–¹æ³•ï¼šåŸºäºå·¥ç¨‹é˜¶æ®µåˆ—å®šä½æŠ€æœ¯åˆ—
            skills, design_positions = self._extract_skills_by_design_column(df)
            if skills:
                print(f"    âœ“ ä»æŠ€æœ¯åˆ—æå–åˆ° {len(skills)} ä¸ªæŠ€èƒ½")
                all_skills.extend(skills)

            # å¤‡ç”¨æ–¹æ³•ï¼šå¦‚æœä¸»æ–¹æ³•å¤±è´¥æˆ–æå–å¤ªå°‘
            if len(all_skills) < 5:
                print(f"    ä½¿ç”¨å¤‡ç”¨æ–¹æ³•è¡¥å……æå–")
                # æ–¹æ³•2ï¼šæŸ¥æ‰¾åˆå¹¶å•å…ƒæ ¼ï¼ˆé™åˆ¶åœ¨è®¾è®¡è¡Œä¸‹æ–¹ï¼‰
                merged_skills = self._find_skills_in_merged_cells(df, design_positions)
                all_skills.extend(merged_skills)

                # æ–¹æ³•3ï¼šå…¨æ–‡æœç´¢ï¼ˆé™åˆ¶åœ¨è®¾è®¡è¡Œä¸‹æ–¹ï¼‰
                if len(all_skills) < 5:
                    fallback_skills = self._extract_skills_fallback(
                        df, design_positions
                    )
                    all_skills.extend(fallback_skills)

        # å»é‡å’Œæ ‡å‡†åŒ–
        final_skills = self._process_and_deduplicate_skills(all_skills)
        return final_skills

    def _extract_skills_by_design_column(
        self, df: pd.DataFrame
    ) -> Tuple[List[str], List[Dict]]:
        """åŸºäºå·¥ç¨‹é˜¶æ®µåˆ—å®šä½å¹¶æå–æŠ€æœ¯åˆ—"""
        skills = []

        # Step 1: æ‰¾åˆ°åŒ…å«"åŸºæœ¬è¨­è¨ˆ"ç­‰å…³é”®è¯çš„åˆ—ä½ç½®
        design_positions = self._find_design_column_positions(df)
        if not design_positions:
            print("    æœªæ‰¾åˆ°å·¥ç¨‹é˜¶æ®µåˆ—")
            return skills, design_positions

        print(f"    æ‰¾åˆ° {len(design_positions)} ä¸ªå·¥ç¨‹é˜¶æ®µåˆ—ä½ç½®")

        # Step 2: å¯¹æ¯ä¸ªæ‰¾åˆ°çš„è®¾è®¡åˆ—ä½ç½®ï¼Œå‘å·¦æŸ¥æ‰¾æ‰€æœ‰æŠ€æœ¯åˆ—
        for design_pos in design_positions:
            # æ‰¾åˆ°æ‰€æœ‰æŠ€æœ¯åˆ—ï¼ˆä¸æ˜¯åªæ‰¾ä¸€ä¸ªï¼‰
            tech_columns = self._find_all_tech_columns_left(df, design_pos)

            if tech_columns:
                print(
                    f"    ä»è®¾è®¡åˆ— {design_pos['col']} (è¡Œ{design_pos['row']}: {design_pos['value']}) å‘å·¦æ‰¾åˆ° {len(tech_columns)} ä¸ªæŠ€æœ¯åˆ—"
                )

                # Step 3: æå–æ¯ä¸ªæŠ€æœ¯åˆ—çš„å†…å®¹
                for tech_column in tech_columns:
                    print(
                        f"      æå–åˆ— {tech_column['col']} (ç±»å‹: {tech_column.get('type', 'æœªçŸ¥')})"
                    )
                    column_skills = self._extract_entire_column_skills(df, tech_column)
                    skills.extend(column_skills)

        return skills, design_positions

    def _find_design_column_positions(self, df: pd.DataFrame) -> List[Dict]:
        """æŸ¥æ‰¾åŒ…å«å·¥ç¨‹é˜¶æ®µå…³é”®è¯çš„åˆ—ä½ç½®"""
        positions = []

        # ä»å³å‘å·¦æ‰«æï¼ˆä¼˜å…ˆæŸ¥æ‰¾å³ä¾§çš„åˆ—ï¼‰
        for col in range(len(df.columns) - 1, -1, -1):
            for row in range(len(df)):  # æœç´¢æ•´ä¸ªåˆ—
                cell = df.iloc[row, col]
                if pd.notna(cell):
                    cell_str = str(cell).strip()
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«å·¥ç¨‹é˜¶æ®µå…³é”®è¯
                    if any(keyword in cell_str for keyword in self.design_keywords):
                        positions.append({"row": row, "col": col, "value": cell_str})
                        break  # è¯¥åˆ—å·²æ‰¾åˆ°ï¼Œç»§ç»­ä¸‹ä¸€åˆ—

        return positions

    def _find_all_tech_columns_left(
        self, df: pd.DataFrame, design_pos: Dict
    ) -> List[Dict]:
        """ä»è®¾è®¡åˆ—ä½ç½®å‘å·¦æŸ¥æ‰¾æ‰€æœ‰æŠ€æœ¯åˆ—"""
        design_row = design_pos["row"]
        design_col = design_pos["col"]
        tech_columns = []

        # å®šä¹‰æœç´¢èŒƒå›´ï¼šåªåœ¨è®¾è®¡è¡Œçš„ä¸‹æ–¹æœç´¢
        search_start_row = design_row  # ä»è®¾è®¡è¡Œå¼€å§‹
        search_end_row = len(df)  # æœç´¢åˆ°è¡¨æ ¼æœ«å°¾

        # ä»è®¾è®¡åˆ—å‘å·¦é€åˆ—æœç´¢
        for col in range(design_col - 1, max(-1, design_col - 20), -1):
            # æ£€æŸ¥è¯¥åˆ—æ˜¯å¦åŒ…å«æŠ€æœ¯å†…å®¹
            tech_info = self._analyze_column_for_tech(
                df, col, search_start_row, search_end_row
            )

            if tech_info and tech_info["score"] >= 2:
                tech_columns.append(tech_info)

        return tech_columns

    def _analyze_column_for_tech(
        self, df: pd.DataFrame, col: int, start_row: int, end_row: int
    ) -> Optional[Dict]:
        """åˆ†ææŸä¸€åˆ—æ˜¯å¦ä¸ºæŠ€æœ¯åˆ—"""
        tech_score = 0
        tech_row_start = None
        column_type = None
        sample_skills = []

        for row in range(start_row, end_row):
            if row >= len(df):
                break

            cell = df.iloc[row, col]
            if pd.notna(cell):
                cell_str = str(cell).strip()

                # æ£€æŸ¥åˆ—æ ‡é¢˜
                if any(keyword in cell_str for keyword in self.tech_column_keywords):
                    tech_score += 10

                    # è¯†åˆ«åˆ—ç±»å‹
                    if any(k in cell_str for k in ["è¨€èª", "ãƒ„ãƒ¼ãƒ«", "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°"]):
                        column_type = "programming"
                    elif "DB" in cell_str or "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹" in cell_str:
                        column_type = "database"
                    elif "OS" in cell_str or "æ©Ÿç¨®" in cell_str:
                        column_type = "os"
                    elif any(k in cell_str for k in ["Git", "SVN", "ãƒãƒ¼ã‚¸ãƒ§ãƒ³"]):
                        column_type = "version_control"

                    if tech_row_start is None:
                        tech_row_start = row

                # æ£€æŸ¥æ˜¯å¦åŒ…å«æŠ€æœ¯å†…å®¹
                if self._cell_contains_tech_content(cell_str):
                    tech_score += 1
                    if tech_row_start is None:
                        tech_row_start = row

                    # æ”¶é›†æ ·æœ¬æŠ€èƒ½
                    if len(sample_skills) < 5:
                        extracted = self._extract_skills_from_text(cell_str)
                        sample_skills.extend(extracted[:2])  # åªå–å‰2ä¸ªé¿å…å¤ªå¤š

        # å¦‚æœè¯¥åˆ—æŠ€æœ¯åˆ†æ•°è¶³å¤Ÿé«˜ï¼Œè¿”å›ä¿¡æ¯
        if tech_score >= 2:
            return {
                "col": col,
                "start_row": tech_row_start or start_row,
                "score": tech_score,
                "type": column_type or "general",
                "sample_skills": sample_skills[:5],  # ä¿ç•™å‰5ä¸ªä½œä¸ºæ ·æœ¬
            }

        return None

    def _cell_contains_tech_content(self, cell_str: str) -> bool:
        """æ£€æŸ¥å•å…ƒæ ¼æ˜¯å¦åŒ…å«æŠ€æœ¯å†…å®¹"""
        # å¿«é€Ÿæ£€æŸ¥å¸¸è§æŠ€æœ¯å…³é”®è¯
        tech_patterns = [
            r"\b(Java|Python|JavaScript|PHP|Ruby|C\+\+|C#|Go|VB|COBOL)\b",
            r"\b(Spring|React|Vue|Angular|Django|Rails|Node\.js|\.NET)\b",
            r"\b(MySQL|PostgreSQL|Oracle|MongoDB|Redis|SQL\s*Server|DB2)\b",
            r"\b(AWS|Azure|GCP|Docker|Kubernetes)\b",
            r"\b(Git|SVN|Jenkins|Maven|TortoiseSVN|GitHub)\b",
            r"\b(Windows|Linux|Unix|Ubuntu|CentOS|win\d+)\b",
            r"\b(Eclipse|IntelliJ|VS\s*Code|Visual\s*Studio|NetBeans)\b",
            r"(HTML|CSS|SQL|XML|JSON|TeraTerm)",
        ]

        cell_upper = cell_str.upper()
        for pattern in tech_patterns:
            if re.search(pattern, cell_str, re.IGNORECASE):
                return True

        # æ£€æŸ¥æ˜¯å¦åŒ…å«é¢„å®šä¹‰çš„æœ‰æ•ˆæŠ€èƒ½
        for skill in VALID_SKILLS:
            if skill.upper() in cell_upper:
                return True

        # ç‰¹æ®Šæƒ…å†µï¼šå•ç‹¬çš„"SE"æˆ–"PG"ä¸ç®—æŠ€èƒ½ï¼Œä½†åœ¨æŠ€æœ¯åˆ—ä¸­å¯èƒ½å‡ºç°
        if cell_str in ["SE", "PG", "PL", "PM"]:
            return False

        return False

    def _extract_entire_column_skills(
        self, df: pd.DataFrame, tech_column: Dict
    ) -> List[str]:
        """æå–æ•´ä¸ªæŠ€æœ¯åˆ—çš„æ‰€æœ‰æŠ€èƒ½"""
        skills = []
        col = tech_column["col"]
        start_row = tech_column["start_row"]

        print(f"        ä»è¡Œ {start_row} å¼€å§‹æå–")

        # æå–è¯¥åˆ—ä»start_rowå¼€å§‹çš„æ‰€æœ‰å†…å®¹
        consecutive_empty = 0
        for row in range(start_row, len(df)):
            cell = df.iloc[row, col]
            if pd.notna(cell):
                cell_str = str(cell).strip()
                consecutive_empty = 0

                # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾æŠ€èƒ½åŒºåŸŸç»“æŸ
                if self._is_column_end(cell_str):
                    break

                # è·³è¿‡èŒä½æ ‡è®°
                if cell_str in ["SE", "PG", "PL", "PM", "TL"]:
                    continue

                # å¤„ç†å¤šè¡Œå†…å®¹ï¼ˆæ¢è¡Œç¬¦åˆ†éš”ï¼‰
                if "\n" in cell_str:
                    lines = cell_str.split("\n")
                    for line in lines:
                        line_skills = self._extract_skills_from_text(line)
                        skills.extend(line_skills)
                else:
                    # å•è¡Œå†…å®¹
                    cell_skills = self._extract_skills_from_text(cell_str)
                    skills.extend(cell_skills)
            else:
                consecutive_empty += 1
                # å¦‚æœè¿ç»­5ä¸ªç©ºå•å…ƒæ ¼ï¼Œå¯èƒ½æŠ€èƒ½åŒºåŸŸå·²ç»“æŸ
                if consecutive_empty >= 5:
                    break

        return skills

    def _is_column_end(self, cell_str: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åˆ°è¾¾æŠ€æœ¯åˆ—ç»“æŸ"""
        # å¦‚æœé‡åˆ°è¿™äº›å†…å®¹ï¼Œè¯´æ˜æŠ€èƒ½åŒºåŸŸç»“æŸ
        end_markers = [
            "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ",
            "æ¡ˆä»¶",
            "çµŒæ­´",
            "å®Ÿç¸¾",
            "æœŸé–“",
            "æ¥­å‹™å†…å®¹",
            "æ‹…å½“",
            "æ¦‚è¦",
            "å‚™è€ƒ",
            "ãã®ä»–",
            "è·æ­´",
            "çµŒé¨“",
            "è³‡æ ¼",
        ]

        # æ—¥æœŸæ ¼å¼ä¹Ÿè¡¨ç¤ºæ–°çš„é¡¹ç›®å¼€å§‹
        if re.match(r"^\d{4}[å¹´/]\d{1,2}[æœˆ/]", cell_str):
            return True

        return any(marker in cell_str for marker in end_markers)

    def _extract_skills_from_text(self, text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–æŠ€èƒ½"""
        skills = []
        text = text.strip()

        if not text:
            return skills

        # ç§»é™¤æ ‡è®°ç¬¦å·
        text = re.sub(r"^[â—â—‹â–³Ã—â˜…â—â—¯â–²â€»ãƒ»\-\s]+", "", text)

        # å¤„ç†æ‹¬å·å†…çš„å†…å®¹
        # ä¾‹å¦‚: "Python AWS (glue/S3/Lambda/EC2/IAM/codecommit)"
        bracket_pattern = r"([^(]+)\s*\(([^)]+)\)"
        bracket_match = re.match(bracket_pattern, text)

        if bracket_match:
            # æ‹¬å·å‰çš„å†…å®¹
            main_part = bracket_match.group(1)
            # æ‹¬å·å†…çš„å†…å®¹
            bracket_content = bracket_match.group(2)

            # æå–ä¸»è¦éƒ¨åˆ†çš„æŠ€èƒ½
            main_skills = self._split_and_validate_skills(main_part)
            skills.extend(main_skills)

            # æå–æ‹¬å·å†…çš„æŠ€èƒ½ï¼ˆé€šå¸¸æ˜¯å…·ä½“çš„æœåŠ¡/æ¨¡å—ï¼‰
            bracket_skills = self._split_and_validate_skills(bracket_content)
            skills.extend(bracket_skills)
        else:
            # æ²¡æœ‰æ‹¬å·ï¼Œç›´æ¥æå–
            skills.extend(self._split_and_validate_skills(text))

        return skills

    def _split_and_validate_skills(self, text: str) -> List[str]:
        """åˆ†å‰²æ–‡æœ¬å¹¶éªŒè¯æŠ€èƒ½"""
        skills = []

        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯ä¸åº”è¯¥è¢«åˆ†å‰²çš„æŠ€èƒ½
        text_stripped = text.strip()

        # æ£€æŸ¥å®Œæ•´æ–‡æœ¬æ˜¯å¦åŒ¹é…ä¸å¯åˆ†å‰²æŠ€èƒ½ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
        for no_split_skill in self.no_split_skills:
            if text_stripped.lower() == no_split_skill.lower():
                if self._is_valid_skill(text_stripped):
                    normalized = self._normalize_skill_name(text_stripped)
                    skills.append(normalized)
                    return skills

        # ä¿æŠ¤ä¸å¯åˆ†å‰²çš„æŠ€èƒ½ï¼šå°†å®ƒä»¬ä¸´æ—¶æ›¿æ¢ä¸ºå ä½ç¬¦
        protected_skills = {}
        protected_text = text
        placeholder_index = 0

        for no_split_skill in self.no_split_skills:
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿›è¡Œä¸åŒºåˆ†å¤§å°å†™çš„åŒ¹é…
            pattern = re.compile(re.escape(no_split_skill), re.IGNORECASE)
            if pattern.search(protected_text):
                placeholder = f"__SKILL_PLACEHOLDER_{placeholder_index}__"
                protected_skills[placeholder] = no_split_skill
                protected_text = pattern.sub(placeholder, protected_text)
                placeholder_index += 1

        # ä½¿ç”¨å¤šç§åˆ†éš”ç¬¦åˆ†å‰²ï¼ˆä½†ä¸åŒ…æ‹¬è¢«ä¿æŠ¤çš„æŠ€èƒ½ï¼‰
        items = re.split(r"[ã€,ï¼Œ/ï¼\s\|ï½œ]+", protected_text)

        for item in items:
            item = item.strip()
            if not item:
                continue

            # æ£€æŸ¥æ˜¯å¦æ˜¯å ä½ç¬¦
            if item in protected_skills:
                # æ¢å¤åŸå§‹æŠ€èƒ½
                original_skill = protected_skills[item]
                if self._is_valid_skill(original_skill):
                    normalized = self._normalize_skill_name(original_skill)
                    skills.append(normalized)
            else:
                # æ™®é€šæŠ€èƒ½éªŒè¯
                if self._is_valid_skill(item):
                    normalized = self._normalize_skill_name(item)
                    skills.append(normalized)

        # å¦‚æœåˆ†å‰²åæ²¡æœ‰æ‰¾åˆ°æŠ€èƒ½ï¼Œå°è¯•å°†æ•´ä¸ªæ–‡æœ¬ä½œä¸ºæŠ€èƒ½
        if not skills and text and self._is_valid_skill(text):
            normalized = self._normalize_skill_name(text)
            skills.append(normalized)

        return skills

    def _find_skills_in_merged_cells(
        self, df: pd.DataFrame, design_positions: List[Dict]
    ) -> List[str]:
        """æŸ¥æ‰¾åˆå¹¶å•å…ƒæ ¼ä¸­çš„æŠ€èƒ½ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰"""
        skills = []

        # è·å–æœ€æ—©çš„è®¾è®¡è¡Œä½ç½®ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        min_design_row = 0
        if design_positions:
            min_design_row = min(pos["row"] for pos in design_positions)

        for row in range(min_design_row, len(df)):  # åªæœç´¢è®¾è®¡è¡Œä¸‹æ–¹
            for col in range(len(df.columns)):
                cell = df.iloc[row, col]
                if pd.notna(cell) and "\n" in str(cell):
                    cell_str = str(cell)
                    lines = cell_str.split("\n")

                    # è®¡ç®—åŒ…å«æŠ€èƒ½çš„è¡Œæ•°
                    skill_count = 0
                    for line in lines:
                        if self._cell_contains_tech_content(line):
                            skill_count += 1

                    # å¦‚æœå¤šè¡ŒåŒ…å«æŠ€èƒ½ï¼Œæå–æ‰€æœ‰
                    if skill_count >= 3:
                        for line in lines:
                            line_skills = self._extract_skills_from_text(line)
                            skills.extend(line_skills)

        return skills

    def _extract_skills_fallback(
        self, df: pd.DataFrame, design_positions: List[Dict]
    ) -> List[str]:
        """å…¨æ–‡æœç´¢æŠ€èƒ½ï¼ˆæœ€åçš„å¤‡ç”¨æ–¹æ³•ï¼‰"""
        skills = []

        # åªæœç´¢è®¾è®¡è¡Œä¸‹æ–¹çš„æ–‡æœ¬
        min_design_row = 0
        if design_positions:
            min_design_row = min(pos["row"] for pos in design_positions)

        # åªå°†è®¾è®¡è¡Œä¸‹æ–¹çš„å†…å®¹è½¬æ¢ä¸ºæ–‡æœ¬
        text_parts = []
        for idx in range(min_design_row, len(df)):
            row = df.iloc[idx]
            row_text = " ".join([str(cell) for cell in row if pd.notna(cell)])
            if row_text.strip():
                text_parts.append(row_text)

        text = "\n".join(text_parts)

        for skill in VALID_SKILLS:
            patterns = [
                rf"\b{re.escape(skill)}\b",
                rf"(?:^|\s|[ã€,ï¼Œ/]){re.escape(skill)}(?:$|\s|[ã€,ï¼Œ/])",
            ]

            for pattern in patterns:
                if re.search(pattern, text, re.IGNORECASE):
                    skills.append(skill)
                    break

        return skills

    def _is_valid_skill(self, skill: str) -> bool:
        """éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆæŠ€èƒ½"""
        if not skill or len(skill) < 1 or len(skill) > 50:
            return False

        skill = skill.strip()

        # æ–°å¢ï¼šæ’é™¤åŒ…å« "os" æˆ– "db" å…³é”®å­—çš„æŠ€èƒ½ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
        skill_lower = skill.lower()
        if "os" in skill_lower or "db" in skill_lower:
            return False

        # æ’é™¤åŒ…å«æ‹¬å·çš„æŠ€èƒ½ï¼ˆåŠè§’å’Œå…¨è§’ï¼‰
        if any(bracket in skill for bracket in ["(", ")", "ï¼ˆ", "ï¼‰"]):
            return False

        # æ’é™¤åŒ…å«æ—¥æ–‡å…³é”®è¯çš„éæŠ€èƒ½å†…å®¹
        exclude_japanese_keywords = [
            "è‡ªå·±PR",
            "è‡ªå·±ç´¹ä»‹",
            "å¿—æœ›å‹•æ©Ÿ",
            "ã‚¢ãƒ”ãƒ¼ãƒ«",
            "ãƒã‚¤ãƒ³ãƒˆ",
            "çµŒæ­´æ›¸",
            "å±¥æ­´æ›¸",
            "ã‚¹ã‚­ãƒ«ã‚·ãƒ¼ãƒˆ",
            "è·å‹™çµŒæ­´",
            "æ°å",
            "æ€§åˆ¥",
            "ç”Ÿå¹´æœˆæ—¥",
            "å¹´é½¢",
            "ä½æ‰€",
            "é›»è©±",
            "å­¦æ­´",
            "è·æ­´",
            "è³‡æ ¼",
            "è¶£å‘³",
            "ç‰¹æŠ€",
            "å‚™è€ƒ",
        ]
        if any(keyword in skill for keyword in exclude_japanese_keywords):
            return False

        # æ’é™¤æ¨¡å¼
        for pattern in EXCLUDE_PATTERNS:
            if re.match(pattern, skill, re.IGNORECASE):
                return False

        # ç‰¹æ®Šæƒ…å†µ
        if skill.upper() == "C":
            return True

        # ç‰¹æ®Šæ’é™¤ï¼šèŒä½æ ‡è®°
        if skill.upper() in ["SE", "PG", "PL", "PM", "TL"]:
            return False

        # æ£€æŸ¥é¢„å®šä¹‰æŠ€èƒ½åˆ—è¡¨
        skill_upper = skill.upper()
        for valid_skill in VALID_SKILLS:
            if valid_skill.upper() == skill_upper:
                return True

        # æ“ä½œç³»ç»Ÿæ¨¡å¼
        if re.match(r"^win\d+$", skill_lower) or re.match(
            r"^Windows\s*\d+$", skill, re.IGNORECASE
        ):
            return True

        # åŒ…å«æŠ€æœ¯å…³é”®è¯
        if re.search(r"[a-zA-Z]", skill) and len(skill) >= 2:
            exclude_words = [
                "è¨­è¨ˆ",
                "è£½é€ ",
                "è©¦é¨“",
                "ãƒ†ã‚¹ãƒˆ",
                "ç®¡ç†",
                "çµŒé¨“",
                "æ‹…å½“",
                "å½¹å‰²",
                "ãƒ•ã‚§ãƒ¼ã‚º",
            ]
            if not any(word in skill for word in exclude_words):
                return True

        return False

    def _normalize_skill_name(self, skill: str) -> str:
        """æ ‡å‡†åŒ–æŠ€èƒ½åç§°"""
        skill = skill.strip()
        # å¤„ç†å†’å·åˆ†éš”çš„æƒ…å†µï¼ˆæ”¯æŒå…¨è§’å’ŒåŠè§’å†’å·ï¼‰
        # ä¾‹å¦‚: "è¨€èª:Java" -> "Java", "DBï¼šPostgreSQL" -> "PostgreSQL"
        if ":" in skill or "ï¼š" in skill:
            # æ›¿æ¢å…¨è§’å†’å·ä¸ºåŠè§’ï¼Œç„¶ååˆ†å‰²
            skill_parts = skill.replace("ï¼š", ":").split(":", 1)
            if len(skill_parts) == 2:
                # å–å†’å·åé¢çš„éƒ¨åˆ†
                skill = skill_parts[1].strip()
                # å¦‚æœå†’å·åé¢ä¸ºç©ºï¼Œè¿”å›åŸå§‹å€¼
                if not skill:
                    skill = skill_parts[0].strip()

        # ç‰¹æ®Šå¤„ç†ï¼šæ“ä½œç³»ç»Ÿæ ‡å‡†åŒ–
        # å¦‚æœåŒ…å« Windowsï¼ˆæ— è®ºå¤§å°å†™ï¼‰ï¼Œç»Ÿä¸€è¿”å› Windows
        if "windows" in skill.lower():
            return "Windows"

        # å¦‚æœåŒ…å« Linuxï¼ˆæ— è®ºå¤§å°å†™ï¼‰ï¼Œç»Ÿä¸€è¿”å› Linux
        if "linux" in skill.lower():
            return "Linux"

        # æŠ€èƒ½åç§°æ˜ å°„
        skill_mapping = {
            # ç¼–ç¨‹è¯­è¨€
            "JAVA": "Java",
            "java": "Java",
            "Javascript": "JavaScript",
            "javascript": "JavaScript",
            "JAVASCRIPT": "JavaScript",
            "typescript": "TypeScript",
            "TYPESCRIPT": "TypeScript",
            "python": "Python",
            "PYTHON": "Python",
            # æ•°æ®åº“
            "MySql": "MySQL",
            "mysql": "MySQL",
            "mybatis": "MyBatis",
            "Mybatis": "MyBatis",
            "MYBATIS": "MyBatis",
            "PostgreSQL": "PostgreSQL",
            "Postgre SQL": "PostgreSQL",
            "SqlServer": "SQL Server",
            "SQLServer": "SQL Server",
            "sqlserver": "SQL Server",
            "SQL SERVER": "SQL Server",
            # æ¡†æ¶
            "spring": "Spring",
            "springboot": "SpringBoot",
            "SpringBoot": "SpringBoot",
            "node.js": "Node.js",
            "Node.JS": "Node.js",
            "nodejs": "Node.js",
            "vue.js": "Vue",
            "react.js": "React",
            "thymeleaf": "Thymeleaf",
            # IDEå’Œå·¥å…·
            "eclipse": "Eclipse",
            "eclipes": "Eclipse",  # å¸¸è§æ‹¼å†™é”™è¯¯
            "ECLIPSE": "Eclipse",
            "vscode": "VS Code",
            "Vscode": "VS Code",
            "VSCode": "VS Code",
            "VScode": "VS Code",
            "VS Code": "VS Code",
            "VS code": "VS Code",
            "vs code": "VS Code",
            "Visual Studio Code": "VS Code",
            "junit": "JUnit",
            "Junit": "JUnit",
            "JUNIT": "JUnit",
            "github": "GitHub",
            "GITHUB": "GitHub",
            "svn": "SVN",
            "Svn": "SVN",
            "TortoiseSVN": "TortoiseSVN",
            "Tortoise SVN": "TortoiseSVN",
            "winmerge": "WinMerge",
            "WINMERGE": "WinMerge",
            "teraterm": "TeraTerm",
            "TERATERM": "TeraTerm",
            "Tera Term": "TeraTerm",
            # åä½œå·¥å…·
            "slack": "Slack",
            "SLACK": "Slack",
            "teams": "Teams",
            "TEAMS": "Teams",
            "ovice": "oVice",
            "Ovice": "oVice",
            # äº‘æœåŠ¡
            "aws": "AWS",
            "Aws": "AWS",
            "azure": "Azure",
            "AZURE": "Azure",
            "Azure SQL DB": "Azure SQL Database",
            # AWSæœåŠ¡æ ‡å‡†åŒ–
            "glue": "AWS Glue",
            "S3": "AWS S3",
            "Lambda": "AWS Lambda",
            "EC2": "AWS EC2",
            "IAM": "AWS IAM",
            "codecommit": "AWS CodeCommit",
            # å…¶ä»–
            "dynamics365": "Dynamics 365",
            "Dynamics365": "Dynamics 365",
            "FO": "Finance and Operations",
            "JP1": "JP1",
            "jp1": "JP1",
        }

        # æ£€æŸ¥æ˜ å°„
        if skill in skill_mapping:
            return skill_mapping[skill]

        # å¤§å°å†™ä¸æ•æ„ŸæŸ¥æ‰¾
        skill_lower = skill.lower()
        for k, v in skill_mapping.items():
            if k.lower() == skill_lower:
                return v

        # æ£€æŸ¥æœ‰æ•ˆæŠ€èƒ½åˆ—è¡¨
        for valid_skill in VALID_SKILLS:
            if valid_skill.lower() == skill_lower:
                return valid_skill

        return skill

    def _process_and_deduplicate_skills(self, skills: List[str]) -> List[str]:
        """å¤„ç†å’Œå»é‡æŠ€èƒ½åˆ—è¡¨"""
        final_skills = []
        seen_lower = set()

        for skill in skills:
            if not skill:
                continue

            normalized = self._normalize_skill_name(skill)
            normalized_lower = normalized.lower()

            # å»é‡ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰
            if normalized_lower not in seen_lower:
                seen_lower.add(normalized_lower)
                final_skills.append(normalized)

        # ä¿æŒåŸå§‹é¡ºåºï¼Œä¸è¿›è¡Œæ’åº
        print(f"    æœ€ç»ˆæå–æŠ€èƒ½æ•°é‡: {len(final_skills)}")
        if final_skills:
            print(f"    å‰10ä¸ªæŠ€èƒ½: {', '.join(final_skills[:10])}")

        return final_skills

    def _dataframe_to_text(self, df: pd.DataFrame) -> str:
        """å°†DataFrameè½¬æ¢ä¸ºæ–‡æœ¬"""
        text_parts = []
        for idx, row in df.iterrows():
            row_text = " ".join([str(cell) for cell in row if pd.notna(cell)])
            if row_text.strip():
                text_parts.append(row_text)
        return "\n".join(text_parts)
