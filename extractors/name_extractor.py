# -*- coding: utf-8 -*-
"""å§“åæå–å™¨ - é’ˆå¯¹æ€§ä¿®å¤ç‰ˆï¼šè§£å†³å…¨è§’ç©ºæ ¼é—®é¢˜"""

from typing import List, Dict, Any
import pandas as pd
import re

from base.base_extractor import BaseExtractor
from base.constants import KEYWORDS
from utils.validation_utils import is_valid_name


class NameExtractor(BaseExtractor):
    """å§“åä¿¡æ¯æå–å™¨ - é’ˆå¯¹æ€§ä¿®å¤ç‰ˆ"""

    def __init__(self):
        super().__init__()
        self.problematic_labels = [
            "å¾—æ„åˆ†é‡",
            "å¾—æ„ åˆ†é‡",
            "å¾—æ„ã€€åˆ†é‡",
            "æ°å",
            "æ° å",
            "æ°ã€€å",
            "åå‰",
            "å å‰",
            "åã€€å‰",
            "ãƒ•ãƒªã‚¬ãƒŠ",
            "ãµã‚ŠãŒãª",
        ]

    def extract(self, all_data: List[Dict[str, Any]]) -> str:
        """æå–å§“å - é’ˆå¯¹æ€§ä¿®å¤ç‰ˆ"""
        candidates = []

        for data in all_data:
            df = data["df"]
            sheet_name = data.get("sheet_name", "Unknown")

            print(f"\nğŸ” å¼€å§‹å§“åæå– - Sheet: {sheet_name}")

            # ä¸“é—¨é’ˆå¯¹[2,0]ä½ç½®çš„"æ°ã€€å"è¿›è¡Œæœç´¢
            specific_candidates = self._search_specific_position(df)
            if specific_candidates:
                print(f"    âœ… åœ¨ç‰¹å®šä½ç½®æ‰¾åˆ° {len(specific_candidates)} ä¸ªå€™é€‰")
                candidates.extend(specific_candidates)

            # é€šç”¨å…³é”®è¯æœç´¢
            general_candidates = self._search_by_keywords_enhanced(df)
            if general_candidates:
                print(f"    âœ… é€šç”¨æœç´¢æ‰¾åˆ° {len(general_candidates)} ä¸ªå€™é€‰")
                candidates.extend(general_candidates)

            # å¤‡ç”¨æœç´¢
            if not candidates:
                backup_candidates = self._search_top_rows_backup(df)
                candidates.extend(backup_candidates)

        if candidates:
            # è¿‡æ»¤å’Œæ’åº
            filtered_candidates = []
            for name, confidence in candidates:
                # æ ‡å‡†åŒ–å§“åï¼ˆå¤„ç†å…¨è§’ç©ºæ ¼ï¼‰
                normalized_name = self._normalize_name(name)

                if not self._is_obvious_label(normalized_name):
                    # éªŒè¯æ ‡å‡†åŒ–åçš„å§“å
                    if is_valid_name(normalized_name):
                        filtered_candidates.append((normalized_name, confidence))
                        print(
                            f"    âœ… ä¿ç•™å€™é€‰: '{name}' -> '{normalized_name}' (ç½®ä¿¡åº¦: {confidence:.2f})"
                        )
                    else:
                        print(f"    âŒ éªŒè¯å¤±è´¥: '{normalized_name}'")
                else:
                    print(f"    âŒ è¿‡æ»¤æ ‡ç­¾: '{name}'")

            if filtered_candidates:
                filtered_candidates.sort(key=lambda x: x[1], reverse=True)
                best_name = filtered_candidates[0][0]
                print(
                    f"\nâœ… æœ€ç»ˆé€‰æ‹©å§“å: '{best_name}' (ç½®ä¿¡åº¦: {filtered_candidates[0][1]:.2f})"
                )
                return best_name

        print("\nâŒ æœªèƒ½æå–åˆ°å§“å")
        return ""

    def _search_specific_position(self, df: pd.DataFrame) -> List[tuple]:
        """ä¸“é—¨æœç´¢[2,0]ä½ç½®çš„æ°åå¯¹åº”çš„[2,3]ä½ç½®"""
        candidates = []

        # æ£€æŸ¥[2,0]æ˜¯å¦åŒ…å«"æ°"
        if len(df) > 2 and len(df.columns) > 0:
            cell_2_0 = df.iloc[2, 0]
            if pd.notna(cell_2_0) and "æ°" in str(cell_2_0):
                print(f"    ğŸ¯ åœ¨[2,0]å‘ç°æ°åå…³é”®è¯: '{cell_2_0}'")

                # æ£€æŸ¥[2,3]ä½ç½®
                if len(df.columns) > 3:
                    cell_2_3 = df.iloc[2, 3]
                    if pd.notna(cell_2_3):
                        value = str(cell_2_3).strip()
                        print(f"    ğŸ¯ åœ¨[2,3]å‘ç°å†…å®¹: '{value}'")

                        # è¿™å°±æ˜¯æˆ‘ä»¬è¦æ‰¾çš„å§“åï¼
                        normalized = self._normalize_name(value)
                        candidates.append((normalized, 5.0))  # ç»™äºˆæœ€é«˜ç½®ä¿¡åº¦
                        print(f"    âœ… ç‰¹å®šä½ç½®å€™é€‰: '{value}' -> '{normalized}'")

        return candidates

    def _search_by_keywords_enhanced(self, df: pd.DataFrame) -> List[tuple]:
        """å¢å¼ºçš„å…³é”®è¯æœç´¢"""
        candidates = []

        for idx in range(min(10, len(df))):
            for col in range(len(df.columns)):
                cell = df.iloc[idx, col]
                if pd.notna(cell):
                    cell_str = str(cell).strip()

                    if any(k in cell_str for k in KEYWORDS["name"]):
                        print(f"    æ‰¾åˆ°å§“åå…³é”®è¯ '{cell_str}' åœ¨ä½ç½® [{idx}, {col}]")

                        # ä¸è¦è·³è¿‡ä»»ä½•å†…å®¹ï¼Œç›´æ¥æœç´¢é™„è¿‘
                        nearby_candidates = self._search_nearby_enhanced(df, idx, col)
                        candidates.extend(nearby_candidates)

        return candidates

    def _search_nearby_enhanced(
        self, df: pd.DataFrame, row: int, col: int
    ) -> List[tuple]:
        """å¢å¼ºçš„é™„è¿‘æœç´¢"""
        candidates = []

        # æœç´¢æ›´å¤§çš„èŒƒå›´
        for r_offset in range(-2, 5):
            for c_offset in range(-2, 20):  # æ‰©å¤§åˆ—æœç´¢èŒƒå›´
                r = row + r_offset
                c = col + c_offset

                if 0 <= r < len(df) and 0 <= c < len(df.columns):
                    value = df.iloc[r, c]
                    if pd.notna(value):
                        value_str = str(value).strip()

                        if value_str and len(value_str) >= 2:
                            # æ ‡å‡†åŒ–å¤„ç†
                            normalized = self._normalize_name(value_str)

                            # ç®€åŒ–éªŒè¯ï¼šåªæ’é™¤æ˜æ˜¾çš„æ ‡ç­¾
                            if not self._is_obvious_label(normalized):
                                # è¿›ä¸€æ­¥éªŒè¯
                                if is_valid_name(normalized):
                                    confidence = self._calculate_confidence(
                                        row, col, r, c, normalized
                                    )
                                    candidates.append((normalized, confidence))
                                    print(
                                        f"      å€™é€‰: '{value_str}' -> '{normalized}' è¡Œ{r}, åˆ—{c}, ç½®ä¿¡åº¦{confidence:.2f}"
                                    )

        return candidates

    def _search_top_rows_backup(self, df: pd.DataFrame) -> List[tuple]:
        """å¤‡ç”¨çš„å‰è¡Œæœç´¢"""
        candidates = []

        for row in range(min(5, len(df))):
            for col in range(min(10, len(df.columns))):
                cell = df.iloc[row, col]
                if pd.notna(cell):
                    cell_str = str(cell).strip()

                    if cell_str and len(cell_str) >= 2:
                        normalized = self._normalize_name(cell_str)

                        if not self._is_obvious_label(normalized) and is_valid_name(
                            normalized
                        ):

                            confidence = 0.5
                            if row <= 2 and col <= 5:
                                confidence += 0.3
                            if len(normalized) >= 2:
                                confidence += 0.3

                            candidates.append((normalized, confidence))
                            print(
                                f"    å¤‡ç”¨: '{cell_str}' -> '{normalized}' è¡Œ{row}, åˆ—{col}"
                            )

        return candidates

    def _normalize_name(self, name: str) -> str:
        """æ ‡å‡†åŒ–å§“åï¼šå¤„ç†å„ç§ç©ºæ ¼"""
        if not name:
            return ""

        # ç§»é™¤å‰åç©ºæ ¼
        name = name.strip()

        # å°†å…¨è§’ç©ºæ ¼æ›¿æ¢ä¸ºåŠè§’ç©ºæ ¼
        name = name.replace("ã€€", " ")

        # ç§»é™¤å¤šä½™çš„ç©ºæ ¼ï¼ˆä¿ç•™å•ä¸ªç©ºæ ¼ç”¨äºå§“ååˆ†éš”ï¼‰
        name = re.sub(r"\s+", " ", name)

        # å¦‚æœæ˜¯å•ä¸ªç©ºæ ¼åˆ†éš”çš„å§“åï¼Œä¿æŒåŸæ ·
        # å¦åˆ™ç§»é™¤æ‰€æœ‰ç©ºæ ¼
        parts = name.split(" ")
        if len(parts) == 2 and all(len(p) >= 1 for p in parts):
            # å§“åæ ¼å¼ï¼šä¿æŒç©ºæ ¼
            return name
        else:
            # å…¶ä»–æƒ…å†µï¼šç§»é™¤ç©ºæ ¼
            return name.replace(" ", "")

    def _is_obvious_label(self, text: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯æ˜æ˜¾çš„æ ‡ç­¾"""
        if not text:
            return True

        text_clean = re.sub(r"\s+", "", text.lower())

        # æ£€æŸ¥é—®é¢˜æ ‡ç­¾
        for label in self.problematic_labels:
            label_clean = re.sub(r"\s+", "", label.lower())
            if text_clean == label_clean:
                return True

        # æ£€æŸ¥æ˜æ˜¾çš„éå§“åè¯æ±‡
        obvious_non_names = [
            "å¹´é½¢",
            "æ€§åˆ¥",
            "å›½ç±",
            "ä½æ‰€",
            "é›»è©±",
            "ãƒ¡ãƒ¼ãƒ«",
            "ç”·æ€§",
            "å¥³æ€§",
            "ç”·",
            "å¥³",
            "æ­³",
            "æ‰",
            "å¹´",
            "æœˆ",
            "æ—¥",
            "çµŒé¨“",
            "ã‚¹ã‚­ãƒ«",
            "æŠ€è¡“",
            "é–‹ç™º",
            "æ¥­å‹™",
            "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ",
            "ã‚·ã‚¹ãƒ†ãƒ ",
            "è¨€èª",
            "ãƒ„ãƒ¼ãƒ«",
            "ç’°å¢ƒ",
            "è³‡æ ¼",
            "å¾—æ„åˆ†é‡",
            "å°‚é–€åˆ†é‡",
            "é–‹ç™ºæŠ€è¡“",
            "æ¥­å‹™çŸ¥è­˜",
            "è‡ªå·±pr",
            "java",
            "javascript",
            "php",
            "python",
            "html",
            "css",
            "sql",
        ]

        for word in obvious_non_names:
            if word.lower() in text_clean:
                return True

        return False

    def _calculate_confidence(
        self,
        base_row: int,
        base_col: int,
        candidate_row: int,
        candidate_col: int,
        value: str,
    ) -> float:
        """è®¡ç®—ç½®ä¿¡åº¦"""
        confidence = 1.0

        # ä½ç½®å› ç´ 
        if candidate_row == base_row:
            confidence *= 1.5

        if candidate_col > base_col and candidate_col - base_col <= 5:
            confidence *= 1.3

        # è·ç¦»å› ç´ 
        distance = abs(candidate_row - base_row) + abs(candidate_col - base_col)
        confidence *= 1.0 / (1 + distance * 0.1)

        # å†…å®¹å› ç´ 
        if len(value) >= 2:
            confidence *= 1.5

        if re.search(r"[ä¸€-é¾¥]", value):
            confidence *= 1.3

        if re.search(r"[A-Za-z]", value):
            confidence *= 1.1

        return confidence
