# -*- coding: utf-8 -*-
"""å§“åæå–å™¨ - å®Œæ•´ä¿®å¤ç‰ˆï¼šè§£å†³è·ç¦»æƒé‡å’Œæœç´¢èŒƒå›´é—®é¢˜"""

from typing import List, Dict, Any
import pandas as pd
import re

from base.base_extractor import BaseExtractor
from base.constants import KEYWORDS
from utils.validation_utils import is_valid_name


class NameExtractor(BaseExtractor):
    """å§“åä¿¡æ¯æå–å™¨ - å®Œæ•´ä¿®å¤ç‰ˆ"""

    def __init__(self):
        super().__init__()
        # å­¦å†ç›¸å…³å…³é”®è¯ï¼Œç”¨äºé¿å…åœ¨å­¦å†åŒºåŸŸæœç´¢å§“å
        self.education_keywords = [
            "å­¦æ­´",
            "æœ€çµ‚å­¦æ­´",
            "å­¦æ ¡",
            "å¤§å­¦",
            "ç ”ç©¶ç§‘",
            "å­¦é™¢",
            "å°‚é–€å­¦æ ¡",
            "é«˜æ ¡",
            "å’æ¥­",
            "åœ¨å­¦",
            "å°‚æ”»",
            "å­¦ç§‘",
            "å­¦éƒ¨",
            "ç ”ç©¶å®¤",
            "åšå£«",
            "ä¿®å£«",
            "å­¦å£«",
            "PhD",
            "Master",
            "Bachelor",
        ]

        # å…³ç³»å’ŒèŒä¸šè¯æ±‡
        self.relationship_keywords = [
            "é…å¶è€…",
            "é…å¶",
            "å¤«",
            "å¦»",
            "ç‹¬èº«",
            "æ—¢å©š",
            "æœªå©š",
            "å®¶æ—",
            "æŠ€è¡“è€…",
            "é–‹ç™ºè€…",
            "ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢",
            "ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼",
            "ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢",
        ]

    def extract(self, all_data: List[Dict[str, Any]]) -> str:
        """æå–å§“å

        Args:
            all_data: åŒ…å«æ‰€æœ‰sheetæ•°æ®çš„åˆ—è¡¨

        Returns:
            æå–çš„å§“åï¼Œå¦‚æœæœªæ‰¾åˆ°è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        candidates = []

        for data in all_data:
            df = data["df"]
            sheet_name = data.get("sheet_name", "Unknown")

            print(f"\nğŸ” å¼€å§‹å§“åæå– - Sheet: {sheet_name}")
            print(f"    è¡¨æ ¼å¤§å°: {df.shape[0]}è¡Œ x {df.shape[1]}åˆ—")

            # æ–¹æ³•1: ç²¾ç¡®æœç´¢å§“åå…³é”®è¯é™„è¿‘ï¼ˆä¿®å¤è·ç¦»æƒé‡é—®é¢˜ï¼‰
            primary_candidates = self._search_name_by_keywords_fixed(df)
            if primary_candidates:
                print(f"    âœ… é€šè¿‡å…³é”®è¯æ‰¾åˆ° {len(primary_candidates)} ä¸ªå€™é€‰å§“å")
                candidates.extend(primary_candidates)

            # æ–¹æ³•2: å¦‚æœä¸»è¦æ–¹æ³•å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æœç´¢ï¼ˆé™åˆ¶åœ¨å‰5è¡Œï¼‰
            if not candidates:
                print("    ä½¿ç”¨å¤‡ç”¨æ–¹æ³•ï¼šå‰5è¡Œæœç´¢")
                backup_candidates = self._search_name_in_top_rows(df)
                candidates.extend(backup_candidates)

        if candidates:
            # è¿‡æ»¤æ— æ•ˆå€™é€‰
            valid_candidates = []
            for name, confidence in candidates:
                if is_valid_name(name) and not self._is_relationship_word(name):
                    valid_candidates.append((name, confidence))
                    print(f"    âœ… æœ‰æ•ˆå€™é€‰: '{name}' (ç½®ä¿¡åº¦: {confidence:.2f})")
                else:
                    print(f"    âŒ è¿‡æ»¤å€™é€‰: '{name}' (éªŒè¯å¤±è´¥æˆ–å…³ç³»è¯æ±‡)")

            if valid_candidates:
                # æŒ‰ç½®ä¿¡åº¦æ’åºï¼Œè¿”å›æœ€ä½³å€™é€‰
                valid_candidates.sort(key=lambda x: x[1], reverse=True)
                best_name = valid_candidates[0][0].strip()
                print(
                    f"\nâœ… æœ€ç»ˆé€‰æ‹©å§“å: '{best_name}' (ç½®ä¿¡åº¦: {valid_candidates[0][1]:.2f})"
                )
                return best_name

        print("\nâŒ æœªèƒ½æå–åˆ°å§“å")
        return ""

    def _search_name_by_keywords_fixed(self, df: pd.DataFrame) -> List[tuple]:
        """é€šè¿‡å§“åå…³é”®è¯æœç´¢å§“å - ä¿®å¤ç‰ˆï¼ˆè§£å†³è·ç¦»æƒé‡é—®é¢˜ï¼‰"""
        candidates = []

        # åªæœç´¢å‰10è¡Œï¼Œé¿å…åœ¨å­¦å†ç­‰åŒºåŸŸæœç´¢
        for idx in range(min(10, len(df))):
            for col in range(len(df.columns)):
                cell = df.iloc[idx, col]
                if pd.notna(cell) and any(k in str(cell) for k in KEYWORDS["name"]):
                    print(f"    æ‰¾åˆ°å§“åå…³é”®è¯ '{cell}' åœ¨ä½ç½® [{idx}, {col}]")

                    # ä¿®å¤åçš„é‚»è¿‘æœç´¢ï¼šåˆ†å±‚æœç´¢ï¼Œå¼ºåŒ–è·ç¦»æƒé‡
                    nearby_candidates = self._search_name_nearby_fixed(df, idx, col)
                    candidates.extend(nearby_candidates)

        return candidates

    def _search_name_nearby_fixed(
        self, df: pd.DataFrame, row: int, col: int
    ) -> List[tuple]:
        """ä¿®å¤åçš„é‚»è¿‘æœç´¢ - åˆ†å±‚æœç´¢ï¼Œå¼ºåŒ–è·ç¦»æƒé‡"""
        candidates = []

        print(f"    å¼€å§‹åˆ†å±‚æœç´¢å§“åå…³é”®è¯[{row},{col}]é™„è¿‘çš„å§“å")

        # ç­–ç•¥1: ä¼˜å…ˆæœç´¢ç›´æ¥é‚»è¿‘ä½ç½®ï¼ˆè·ç¦»1-3ï¼‰
        priority_candidates = self._search_immediate_vicinity(df, row, col)

        # ç­–ç•¥2: æ‰©å¤§æœç´¢ä½†å¼ºåŒ–è·ç¦»æƒé‡ï¼ˆè·ç¦»4-8ï¼‰
        extended_candidates = self._search_extended_area(df, row, col)

        # åˆå¹¶å€™é€‰ï¼Œä¼˜å…ˆçº§å€™é€‰è·å¾—é¢å¤–æƒé‡
        for name, conf in priority_candidates:
            enhanced_conf = conf * 2.0  # é‚»è¿‘å€™é€‰è·å¾—åŒå€æƒé‡
            candidates.append((name, enhanced_conf))
            print(
                f"      ğŸ¯ ä¼˜å…ˆå€™é€‰: '{name}' ç½®ä¿¡åº¦{enhanced_conf:.2f} (åŸ{conf:.2f})"
            )

        for name, conf in extended_candidates:
            candidates.append((name, conf))
            print(f"      ğŸ“ æ‰©å±•å€™é€‰: '{name}' ç½®ä¿¡åº¦{conf:.2f}")

        return candidates

    def _search_immediate_vicinity(
        self, df: pd.DataFrame, row: int, col: int
    ) -> List[tuple]:
        """æœç´¢ç›´æ¥é‚»è¿‘ä½ç½®ï¼ˆè·ç¦»1-3ï¼‰"""
        candidates = []

        # åªæœç´¢éå¸¸è¿‘çš„ä½ç½®
        for r_offset in range(-1, 3):  # 4è¡ŒèŒƒå›´ï¼šä¸Š1è¡Œåˆ°ä¸‹2è¡Œ
            for c_offset in range(-1, 8):  # 9åˆ—èŒƒå›´ï¼šå·¦1åˆ—åˆ°å³7åˆ—
                r = row + r_offset
                c = col + c_offset

                if 0 <= r < len(df) and 0 <= c < len(df.columns):
                    distance = abs(r_offset) + abs(c_offset)
                    if distance <= 3:  # åªè€ƒè™‘è·ç¦»3ä»¥å†…
                        value = df.iloc[r, c]
                        if pd.notna(value):
                            value_str = str(value).strip()

                            if self._could_be_name(value_str):
                                confidence = self._calculate_proximity_confidence(
                                    r_offset, c_offset, value_str
                                )
                                candidates.append((value_str, confidence))
                                print(
                                    f"        ğŸ“ è¿‘è·ç¦»å€™é€‰[{r},{c}]: '{value_str}' è·ç¦»{distance} ç½®ä¿¡åº¦{confidence:.2f}"
                                )

        return candidates

    def _search_extended_area(
        self, df: pd.DataFrame, row: int, col: int
    ) -> List[tuple]:
        """æœç´¢æ‰©å±•åŒºåŸŸï¼ˆè·ç¦»4-8ï¼‰"""
        candidates = []

        # æ‰©å¤§æœç´¢ä½†é™åˆ¶èŒƒå›´ï¼ˆæ¯”åŸæ¥å°å¾ˆå¤šï¼‰
        for r_offset in range(-2, 4):  # 6è¡ŒèŒƒå›´
            for c_offset in range(-2, 12):  # 14åˆ—èŒƒå›´ï¼ˆåŸæ¥æ˜¯22åˆ—ï¼‰
                r = row + r_offset
                c = col + c_offset

                if 0 <= r < len(df) and 0 <= c < len(df.columns):
                    distance = abs(r_offset) + abs(c_offset)
                    if 4 <= distance <= 8:  # åªè€ƒè™‘ä¸­ç­‰è·ç¦»
                        value = df.iloc[r, c]
                        if pd.notna(value):
                            value_str = str(value).strip()

                            if self._could_be_name(value_str):
                                confidence = self._calculate_distance_confidence(
                                    r_offset, c_offset, value_str
                                )
                                candidates.append((value_str, confidence))
                                print(
                                    f"        ğŸ“ æ‰©å±•å€™é€‰[{r},{c}]: '{value_str}' è·ç¦»{distance} ç½®ä¿¡åº¦{confidence:.2f}"
                                )

        return candidates

    def _calculate_proximity_confidence(
        self, r_offset: int, c_offset: int, value: str
    ) -> float:
        """è®¡ç®—é‚»è¿‘å€™é€‰çš„ç½®ä¿¡åº¦"""
        confidence = 3.0  # åŸºç¡€é«˜ç½®ä¿¡åº¦

        # å¼ºåŒ–è·ç¦»æƒé‡ï¼ˆé‚»è¿‘åŒºåŸŸï¼Œè·ç¦»æƒé‡å¾ˆé‡è¦ï¼‰
        distance = abs(r_offset) + abs(c_offset)
        distance_weight = 1.0 / (1 + distance * 0.5)  # å¼ºåŒ–è·ç¦»æƒé‡
        confidence *= distance_weight

        # ä½ç½®åå¥½ï¼šå³ä¾§å’Œä¸‹æ–¹ä¼˜å…ˆï¼ˆç¬¦åˆæ—¥æœ¬ç®€å†å¸ƒå±€ï¼‰
        if c_offset > 0:  # å³ä¾§
            confidence *= 1.4
        if r_offset >= 0:  # åŒè¡Œæˆ–ä¸‹æ–¹
            confidence *= 1.3
        if r_offset > 0 and c_offset > 0:  # å³ä¸‹æ–¹
            confidence *= 1.2

        # é•¿åº¦æƒé‡ï¼ˆä½†ä¸è¦è¿‡åº¦åå‘é•¿æ–‡æœ¬ï¼‰
        if len(value) >= 2:
            confidence *= 1.2  # é™ä½é•¿åº¦æƒé‡å½±å“
        elif len(value) == 1:
            # å•å­—ç¬¦ä¸­æ–‡å§“åä»ç„¶æœ‰æ•ˆï¼ˆå¦‚"ä»˜"ï¼‰
            if re.search(r"[ä¸€-é¾¥]", value):
                confidence *= 1.1  # ç•¥å¾®æå‡ä¸­æ–‡å•å­—ç¬¦
                print(f"          ğŸˆ¯ å•å­—ç¬¦ä¸­æ–‡å§“å: '{value}'")

        return confidence

    def _calculate_distance_confidence(
        self, r_offset: int, c_offset: int, value: str
    ) -> float:
        """è®¡ç®—è¿œè·ç¦»å€™é€‰çš„ç½®ä¿¡åº¦"""
        confidence = 1.0  # è¾ƒä½åŸºç¡€ç½®ä¿¡åº¦

        # å¼ºåŒ–è·ç¦»æƒ©ç½šï¼ˆæ¯”åŸæ¥å¼º3å€ï¼‰
        distance = abs(r_offset) + abs(c_offset)
        distance_weight = 1.0 / (1 + distance * 0.3)  # æ›´å¼ºçš„è·ç¦»æƒ©ç½šï¼ˆåŸæ¥æ˜¯0.1ï¼‰
        confidence *= distance_weight

        # ä½ç½®åå¥½
        if c_offset > 0:  # å³ä¾§
            confidence *= 1.2
        if r_offset >= 0:  # åŒè¡Œæˆ–ä¸‹æ–¹
            confidence *= 1.1

        # è¿œè·ç¦»æ—¶æ›´ä¾èµ–é•¿åº¦åˆ¤æ–­
        if len(value) >= 3:
            confidence *= 1.3
        elif len(value) == 2:
            confidence *= 1.1
        else:
            confidence *= 0.7  # å•å­—ç¬¦åœ¨è¿œè·ç¦»ç½®ä¿¡åº¦é™ä½

        return confidence

    def _could_be_name(self, text: str) -> bool:
        """å¿«é€Ÿåˆ¤æ–­æ˜¯å¦å¯èƒ½æ˜¯å§“å"""
        text = text.strip()

        if not text or len(text) > 10:
            return False

        # å¿…é¡»åŒ…å«æ–‡å­—å­—ç¬¦
        if not re.search(r"[ä¸€-é¾¥ã-ã‚“ã‚¡-ãƒ³a-zA-Z]", text):
            return False

        # å¿«é€Ÿæ’é™¤æ˜æ˜¾ä¸æ˜¯å§“åçš„
        obvious_non_names = [
            "åå‰",
            "æ°å",
            "ãƒ•ãƒªã‚¬ãƒŠ",
            "æ€§åˆ¥",
            "å¹´é½¢",
            "å›½ç±",
            "ç”·",
            "å¥³",
            "æ­³",
            "æ‰",
            "å¹´",
            "æœˆ",
            "æ—¥",
            "çµŒé¨“",
            "ã‚¹ã‚­ãƒ«",
            "æŠ€è¡“",
            "é–‹ç™º",
            "å­¦æ­´",
            "ä½æ‰€",
            "é›»è©±",
            "ãƒ¡ãƒ¼ãƒ«",
            "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ",
            "ã‚·ã‚¹ãƒ†ãƒ ",
            "æ¥­å‹™",
            "æ‹…å½“",
            "ãƒãƒ¼ãƒ ",
            "éƒ¨ç½²",
        ]

        if any(word in text for word in obvious_non_names):
            return False

        # æ’é™¤å…³ç³»è¯æ±‡
        if any(word in text for word in self.relationship_keywords):
            return False

        # æ’é™¤å­¦å†ç›¸å…³
        if any(word in text for word in self.education_keywords):
            return False

        return True

    def _is_relationship_word(self, text: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯å…³ç³»è¯æ±‡"""
        return any(word in text for word in self.relationship_keywords)

    def _search_name_in_top_rows(self, df: pd.DataFrame) -> List[tuple]:
        """åœ¨å‰å‡ è¡Œæœç´¢å¯èƒ½çš„å§“åï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰"""
        candidates = []

        print("    ğŸ”„ æ‰§è¡Œå¤‡ç”¨æœç´¢ï¼šå‰5è¡ŒÃ—å‰8åˆ—")

        # åªæœç´¢å‰5è¡Œï¼Œæ¯è¡Œçš„å‰8åˆ—
        for row in range(min(5, len(df))):
            for col in range(min(8, len(df.columns))):
                cell = df.iloc[row, col]
                if pd.notna(cell):
                    cell_str = str(cell).strip()

                    # è·³è¿‡æ˜æ˜¾ä¸æ˜¯å§“åçš„å†…å®¹
                    if not self._could_be_name(cell_str):
                        continue

                    # è·³è¿‡å­¦å†åŒºåŸŸ
                    if self._is_in_education_area(df, row, col):
                        continue

                    if is_valid_name(cell_str) and not self._is_relationship_word(
                        cell_str
                    ):
                        # ç»™äºˆè¾ƒä½çš„ç½®ä¿¡åº¦
                        confidence = 0.5

                        # ä½ç½®æƒé‡ï¼šå³ä¸Šè§’ä¸ªäººä¿¡æ¯åŒºåŸŸ
                        if row <= 3 and col >= 3:
                            confidence += 0.4

                        # é•¿åº¦æƒé‡ï¼ˆå¹³è¡¡å¤„ç†ï¼‰
                        if len(cell_str.strip()) >= 2:
                            confidence += 0.3
                        elif len(cell_str.strip()) == 1 and re.search(
                            r"[ä¸€-é¾¥]", cell_str
                        ):
                            # å•å­—ç¬¦ä¸­æ–‡å§“åä¹Ÿç»™äºˆåˆç†ç½®ä¿¡åº¦
                            confidence += 0.2

                        candidates.append((cell_str, confidence))
                        print(
                            f"    ğŸ“ å¤‡ç”¨å€™é€‰: '{cell_str}' è¡Œ{row}åˆ—{col} ç½®ä¿¡åº¦{confidence:.2f}"
                        )

        return candidates

    def _is_in_education_area(self, df: pd.DataFrame, row: int, col: int) -> bool:
        """æ£€æŸ¥æ˜¯å¦åœ¨å­¦å†åŒºåŸŸ"""
        if 0 <= row < len(df):
            row_data = df.iloc[row]
            row_text = " ".join([str(cell) for cell in row_data if pd.notna(cell)])

            if any(keyword in row_text for keyword in self.education_keywords):
                return True

        return False
