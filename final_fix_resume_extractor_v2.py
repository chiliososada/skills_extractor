# final_fix_resume_extractor_v2.py - ä¼˜åŒ–åˆå¹¶å•å…ƒæ ¼ä¸­çš„æŠ€èƒ½æå–
# -*- coding: utf-8 -*-

import pandas as pd
import numpy as np
import re
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Union, Tuple, Set
from collections import defaultdict, Counter


class FinalFixResumeExtractor:
    """æœ€ç»ˆä¿®å¤ç‰ˆç®€å†æå–å™¨ - V2ç‰ˆä¼˜åŒ–åˆå¹¶å•å…ƒæ ¼æŠ€èƒ½æå–"""

    def __init__(self):
        self.template = {
            "name": "",
            "gender": None,
            "age": "",
            "nationality": None,
            "arrival_year_japan": None,
            "skills": [],
            "experience": "",
            "japanese_level": "",
        }

        # å…¨è§’è½¬åŠè§’çš„è½¬æ¢è¡¨
        self.trans_table = str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™", "0123456789")

        # æ‰©å±•çš„æŠ€èƒ½æ ‡è®°ç¬¦å·
        self.skill_marks = ["â—", "â—‹", "â–³", "Ã—", "â˜…", "â—", "â—¯", "â–²", "â€»"]

        # Excelæ—¥æœŸèµ·å§‹ç‚¹ï¼š1900å¹´1æœˆ1æ—¥
        self.excel_epoch = datetime(1900, 1, 1)

        # çœŸæ­£çš„æŠ€èƒ½å…³é”®è¯ï¼ˆæ ‡å‡†åŒ–åçš„åç§°ï¼‰
        self.valid_skills = {
            # ç¼–ç¨‹è¯­è¨€
            "Java",
            "JAVA",
            "Python",
            "JavaScript",
            "TypeScript",
            "C",
            "C++",
            "C#",
            "C/C++",
            "PHP",
            "Ruby",
            "Go",
            "Kotlin",
            "Swift",
            "Scala",
            "Rust",
            "VB.NET",
            "VB",
            "VBA",
            "COBOL",
            "Perl",
            "R",
            "Objective-C",
            # å‰ç«¯
            "HTML",
            "HTML5",
            "CSS",
            "CSS3",
            "React",
            "React.js",
            "Vue",
            "Vue.js",
            "Angular",
            "jQuery",
            "Bootstrap",
            "Webpack",
            "Sass",
            "Less",
            # åç«¯æ¡†æ¶
            "Spring",
            "SpringBoot",
            "SpringMVC",
            "Struts",
            "Struts2",
            "Django",
            "Flask",
            "Rails",
            "Express",
            "Node.js",
            ".NET",
            "ASP.NET",
            "Laravel",
            "Thymeleaf",
            "JSF",
            "JSP",
            "Servlet",
            "Java Servlet",
            "Hibernate",
            "MyBatis",
            "Mybatis",
            "JPA",
            # æ•°æ®åº“
            "MySQL",
            "PostgreSQL",
            "Oracle",
            "SQL Server",
            "SQLServer",
            "MongoDB",
            "Redis",
            "DB2",
            "SQLite",
            "Access",
            "Sybase",
            "Azure SQL DB",
            "PL/SQL",
            "Aurora",
            # å·¥å…·å’Œå¹³å°
            "AWS",
            "Azure",
            "GCP",
            "Docker",
            "Kubernetes",
            "Git",
            "GitHub",
            "GitLab",
            "SVN",
            "TortoiseSVN",
            "Jenkins",
            "Maven",
            "Gradle",
            # OS
            "Windows",
            "Windows 10",
            "Linux",
            "Unix",
            "Solaris",
            "DOS/V",
            "Win95/98",
            "win10",
            "Ubuntu",
            "CentOS",
            "RedHat",
            # æœåŠ¡å™¨
            "Apache",
            "Nginx",
            "Tomcat",
            "WebSphere",
            "JBoss",
            "JBOSS",
            "IIS",
            # IDEå’Œå·¥å…·
            "Eclipse",
            "IntelliJ",
            "VS Code",
            "Visual Studio",
            "Android Studio",
            "NetBeans",
            "Xcode",
            "A5M2",
            "WinMerge",
            "WinSCP",
            "Sourcetree",
            "Postman",
            "Fiddler",
            "Charles",
            "Form Designer",
            # æµ‹è¯•å·¥å…·
            "JUnit",
            "Junit",
            "Selenium",
            "JMeter",
            "Jmeter",
            "Spock",
            # å…¶ä»–æŠ€æœ¯
            "XML",
            "JSON",
            "REST",
            "SOAP",
            "Ajax",
            "Microservices",
            "Shell",
            "Bash",
            "PowerShell",
            "VBScript",
            # ç§»åŠ¨å¼€å‘
            "Android",
            "iOS",
            "React Native",
            "Flutter",
            # å…¶ä»–æ¡†æ¶å’Œåº“
            "TERASOLUNA",
            "OutSystems",
            "Wacs",
            # Webç›¸å…³
            "PHP/HTML",
            "Jquery",
            "JAVASCRIPT",
        }

        # éœ€è¦æ’é™¤çš„éæŠ€èƒ½å†…å®¹
        self.exclude_patterns = [
            r"^\d{4}[-/]\d{2}[-/]\d{2}",
            r"^\d{2,4}å¹´\d{1,2}æœˆ",
            r"\d+äºº",
            r"äººä»¥[ä¸‹ä¸Š]",
            r"^(åŸºæœ¬|è©³ç´°)è¨­è¨ˆ$",
            r"^è£½é€ $",
            r"^(å˜ä½“|çµåˆ|ç·åˆ|é‹ç”¨)[è©¦é¨“ãƒ†ã‚¹ãƒˆ]",
            r"^ä¿å®ˆé‹ç”¨$",
            r"^è¦ä»¶å®šç¾©$",
            r"^(SE|PG|PL|PM|TL)$",
            r"^ç®¡ç†$",
            r"ç®¡ç†çµŒé¨“",
            r"^æ•™\s*è‚²$",
            r"æ¥­å‹™çµŒæ­´",
            r"ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ",
            r"^ãã®ä»–$",
            r"^éå»ã®",
            r"ã€.*ã€‘",
            r"^[A-BD-Z]$",
            r"^æºå¸¯$",
            r"^E-mail$",
        ]

        # å…³é”®è¯å®šä¹‰
        self.keywords = {
            "name": ["æ°å", "æ° å", "åå‰", "ãƒ•ãƒªã‚¬ãƒŠ", "Name", "åã€€å‰", "å§“å"],
            "age": [
                "å¹´é½¢",
                "å¹´é¾„",
                "å¹´ä»¤",
                "æ­³",
                "æ‰",
                "Age",
                "å¹´ã€€é½¢",
                "ç”Ÿå¹´æœˆ",
                "æº€",
            ],
            "gender": ["æ€§åˆ¥", "æ€§åˆ«", "Gender", "æ€§ã€€åˆ¥"],
            "nationality": ["å›½ç±", "å‡ºèº«å›½", "å‡ºèº«åœ°", "Nationality", "å›½ã€€ç±"],
            "experience": [
                "çµŒé¨“å¹´æ•°",
                "å®Ÿå‹™çµŒé¨“",
                "é–‹ç™ºçµŒé¨“",
                "ã‚½ãƒ•ãƒˆé–¢é€£æ¥­å‹™çµŒé¨“å¹´æ•°",
                "ITçµŒé¨“",
                "æ¥­å‹™çµŒé¨“",
                "çµŒé¨“",
                "å®Ÿå‹™å¹´æ•°",
                "Experience",
                "ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢çµŒé¨“",
                "çµŒé¨“å¹´æœˆ",
                "è·æ­´",
                "ITçµŒé¨“å¹´æ•°",
                "ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã‚½ãƒ•ãƒˆã‚¦ã‚¨ã‚¢é–¢é€£æ¥­å‹™",
                "å®Ÿå‹™å¹´æ•°",
            ],
            "arrival": [
                "æ¥æ—¥",
                "æ¸¡æ—¥",
                "å…¥å›½",
                "æ—¥æœ¬æ»åœ¨å¹´æ•°",
                "æ»åœ¨å¹´æ•°",
                "åœ¨æ—¥å¹´æ•°",
                "æ¥æ—¥å¹´",
                "æ¥æ—¥æ™‚æœŸ",
                "æ¥æ—¥å¹´æœˆ",
                "æ¥æ—¥å¹´åº¦",
            ],
            "japanese": [
                "æ—¥æœ¬èª",
                "æ—¥èª",
                "JLPT",
                "æ—¥æœ¬èªèƒ½åŠ›",
                "èªå­¦åŠ›",
                "è¨€èªèƒ½åŠ›",
                "æ—¥æœ¬èªãƒ¬ãƒ™ãƒ«",
                "Japanese",
            ],
            "education": [
                "å­¦æ­´",
                "å­¦æ ¡",
                "å¤§å­¦",
                "å’æ¥­",
                "å°‚é–€å­¦æ ¡",
                "é«˜æ ¡",
                "æœ€çµ‚å­¦æ­´",
            ],
            "skills": [
                "æŠ€è¡“",
                "ã‚¹ã‚­ãƒ«",
                "è¨€èª",
                "DB",
                "OS",
                "ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯",
                "ãƒ„ãƒ¼ãƒ«",
                "Skills",
                "å¼€å‘è¯­è¨€",
                "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èª",
                "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹",
                "é–‹ç™ºç’°å¢ƒ",
                "æŠ€è¡“çµŒé¨“",
            ],
        }

    def extract_from_excel(self, file_path: str) -> Dict:
        """ä»Excelæ–‡ä»¶æå–ç®€å†ä¿¡æ¯"""
        try:
            # è¯»å–æ‰€æœ‰sheets
            all_sheets = pd.read_excel(file_path, sheet_name=None)

            result = self.template.copy()

            # æ”¶é›†æ‰€æœ‰æ•°æ®
            all_data = []
            for sheet_name, df in all_sheets.items():
                all_data.append(
                    {
                        "sheet_name": sheet_name,
                        "df": df,
                        "text": self._dataframe_to_text(df),
                    }
                )

            # æå–å„ä¸ªå­—æ®µ
            result["name"] = self._extract_name(all_data)
            result["gender"] = self._extract_gender(all_data)
            result["age"] = self._extract_age_final_fix(all_data)
            result["nationality"] = self._extract_nationality_final_fix(all_data)
            result["arrival_year_japan"] = self._extract_arrival_year_final_fix(
                all_data
            )
            result["experience"] = self._extract_experience_final_fix(all_data)
            result["japanese_level"] = self._extract_japanese_level(all_data)
            result["skills"] = self._extract_skills_v2(all_data)  # ä½¿ç”¨V2ç‰ˆæœ¬

            return result

        except Exception as e:
            print(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            import traceback

            traceback.print_exc()
            return {"error": str(e)}

    def _extract_skills_v2(self, all_data: List[Dict]) -> List[str]:
        """åŸºäºè¡¨æ ¼ç»“æ„çš„æŠ€æœ¯å…³é”®å­—æå–V2ç‰ˆ - ä¼˜åŒ–åˆå¹¶å•å…ƒæ ¼å¤„ç†"""
        all_skills = []

        for data in all_data:
            df = data["df"]
            sheet_name = data.get("sheet_name", "Unknown")

            print(f"\nğŸ” å¼€å§‹æŠ€æœ¯å…³é”®å­—æå–V2 - Sheet: {sheet_name}")
            print(f"    è¡¨æ ¼å¤§å°: {df.shape[0]}è¡Œ x {df.shape[1]}åˆ—")

            # æ–¹æ³•1: ç›´æ¥æœç´¢åŒ…å«å¤šä¸ªæŠ€èƒ½çš„åˆå¹¶å•å…ƒæ ¼
            merged_cell_skills = self._find_skills_in_merged_cells(df)
            if merged_cell_skills:
                print(f"    âœ“ ä»åˆå¹¶å•å…ƒæ ¼æå–åˆ° {len(merged_cell_skills)} ä¸ªæŠ€èƒ½")
                all_skills.extend(merged_cell_skills)

            # æ–¹æ³•2: åŸºäºè®¾è®¡åˆ—çš„ç»“æ„åŒ–æœç´¢
            design_positions = self._find_design_columns(df)
            if design_positions:
                print(f"    âœ“ æ‰¾åˆ°è®¾è®¡åˆ—ä½ç½®: {len(design_positions)}ä¸ª")

                # åœ¨è®¾è®¡åˆ—é™„è¿‘æŸ¥æ‰¾æŠ€èƒ½
                skill_start_position = self._find_skill_start_row_v2(
                    df, design_positions
                )
                if skill_start_position:
                    print(
                        f"    âœ“ æŠ€æœ¯å…³é”®å­—èµ·å§‹ä½ç½®: è¡Œ{skill_start_position['row']}, åˆ—{skill_start_position['col']}"
                    )
                    skills = self._extract_skills_from_column_v2(
                        df, skill_start_position
                    )
                    all_skills.extend(skills)

            # æ–¹æ³•3: å¤‡ç”¨æ–¹æ³•
            if len(all_skills) < 3:  # å¦‚æœæå–çš„æŠ€èƒ½å¤ªå°‘ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•
                print(f"    ä½¿ç”¨å¤‡ç”¨æ–¹æ³•è¡¥å……æŠ€èƒ½æå–")
                fallback_skills = self._extract_skills_fallback(df)
                all_skills.extend(fallback_skills)

        # å»é‡å’Œæ ‡å‡†åŒ–
        final_skills = self._process_and_deduplicate_skills(all_skills)
        return final_skills

    def _find_skills_in_merged_cells(self, df: pd.DataFrame) -> List[str]:
        """ä¸“é—¨æŸ¥æ‰¾åŒ…å«å¤šä¸ªæŠ€èƒ½çš„åˆå¹¶å•å…ƒæ ¼"""
        skills = []
        print(f"    æŸ¥æ‰¾åˆå¹¶å•å…ƒæ ¼ä¸­çš„æŠ€èƒ½...")

        # éå†å‰50è¡Œçš„æ‰€æœ‰å•å…ƒæ ¼
        for row in range(min(50, len(df))):
            for col in range(len(df.columns)):
                cell = df.iloc[row, col]
                if pd.notna(cell):
                    cell_str = str(cell).strip()

                    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ¢è¡Œç¬¦ï¼ˆåˆå¹¶å•å…ƒæ ¼çš„ç‰¹å¾ï¼‰
                    if "\n" in cell_str:
                        lines = cell_str.split("\n")

                        # ç»Ÿè®¡åŒ…å«æŠ€èƒ½çš„è¡Œæ•°
                        skill_lines = []
                        for line in lines:
                            line = line.strip()
                            if line and self._line_contains_skill(line):
                                skill_lines.append(line)

                        # å¦‚æœè¶…è¿‡3è¡ŒåŒ…å«æŠ€èƒ½ï¼Œå¾ˆå¯èƒ½æ˜¯æŠ€èƒ½åˆ—è¡¨
                        if len(skill_lines) >= 3:
                            print(
                                f"      å‘ç°æŠ€èƒ½åˆå¹¶å•å…ƒæ ¼ [{row},{col}]: {len(skill_lines)}ä¸ªæŠ€èƒ½è¡Œ"
                            )

                            # æå–æ‰€æœ‰æŠ€èƒ½
                            for line in lines:
                                line_skills = self._extract_skills_from_line(line)
                                skills.extend(line_skills)

                            # æ‰“å°å‰å‡ ä¸ªæŠ€èƒ½
                            if skills:
                                print(f"      æå–åˆ°çš„æŠ€èƒ½: {', '.join(skills[:5])}...")

        return skills

    def _line_contains_skill(self, line: str) -> bool:
        """æ£€æŸ¥ä¸€è¡Œæ˜¯å¦åŒ…å«æŠ€èƒ½"""
        line = line.strip().upper()

        # å¿«é€Ÿæ£€æŸ¥æ˜¯å¦åŒ…å«å¸¸è§æŠ€èƒ½å…³é”®è¯
        skill_keywords = [
            "JAVA",
            "PYTHON",
            "SCRIPT",
            "HTML",
            "CSS",
            "SQL",
            "SPRING",
            "REACT",
            "VUE",
            "ANGULAR",
            "NODE",
            "PHP",
            "RUBY",
            "KOTLIN",
            "SWIFT",
            "LINUX",
            "WINDOWS",
            "DOCKER",
        ]

        for keyword in skill_keywords:
            if keyword in line:
                return True

        # æ£€æŸ¥æ˜¯å¦åŒ¹é…æœ‰æ•ˆæŠ€èƒ½
        for skill in self.valid_skills:
            if skill.upper() in line:
                return True

        return False

    def _extract_skills_from_line(self, line: str) -> List[str]:
        """ä»ä¸€è¡Œæ–‡æœ¬ä¸­æå–æŠ€èƒ½"""
        skills = []
        line = line.strip()

        # ç§»é™¤å¼€å¤´çš„æ ‡è®°ç¬¦å·
        line = re.sub(r"^[â—â—‹â–³Ã—â˜…â—â—¯â–²â€»ãƒ»\-\s]+", "", line)

        if not line:
            return []

        # å°è¯•å¤šç§åˆ†éš”ç¬¦
        items = re.split(r"[ã€,ï¼Œ/ï¼\s]+", line)

        for item in items:
            item = item.strip()
            if item and self._is_valid_skill_v2(item):
                normalized = self._normalize_skill_name(item)
                skills.append(normalized)

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æŠ€èƒ½ï¼Œä½†è¡Œæœ¬èº«å¯èƒ½å°±æ˜¯ä¸€ä¸ªæŠ€èƒ½
        if not skills and line and self._is_valid_skill_v2(line):
            normalized = self._normalize_skill_name(line)
            skills.append(normalized)

        return skills

    def _find_skill_start_row_v2(
        self, df: pd.DataFrame, design_positions: List[Dict]
    ) -> Optional[Dict]:
        """æŸ¥æ‰¾æŠ€æœ¯å…³é”®å­—èµ·å§‹è¡Œ - V2ç‰ˆæœ¬"""
        if not design_positions:
            return None

        # è·å–è®¾è®¡åˆ—çš„ä½ç½®ä¿¡æ¯
        design_rows = [pos["row"] for pos in design_positions]
        design_cols = [pos["col"] for pos in design_positions]

        min_design_row = min(design_rows)
        max_design_row = max(design_rows)
        min_design_col = min(design_cols)

        print(
            f"    è®¾è®¡åˆ—èŒƒå›´: è¡Œ{min_design_row}-{max_design_row}, æœ€å·¦åˆ—{min_design_col}"
        )

        # æ‰©å¤§æœç´¢èŒƒå›´
        candidates = []

        # æœç´¢è®¾è®¡è¡Œå‰åçš„åŒºåŸŸ
        for row in range(
            max(0, min_design_row - 15), min(len(df), max_design_row + 20)
        ):
            # é‡ç‚¹æœç´¢è®¾è®¡åˆ—å·¦ä¾§
            for col in range(0, min(len(df.columns), min_design_col + 3)):
                cell = df.iloc[row, col]
                if pd.notna(cell):
                    cell_str = str(cell).strip()

                    # æ£€æŸ¥å•å…ƒæ ¼å†…å®¹
                    found_skills = []

                    # å¦‚æœåŒ…å«æ¢è¡Œç¬¦ï¼ŒæŒ‰è¡Œæ£€æŸ¥
                    if "\n" in cell_str:
                        lines = cell_str.split("\n")
                        for line in lines:
                            line_skills = self._extract_skills_from_line(line)
                            found_skills.extend(line_skills)
                    else:
                        # ç›´æ¥æå–æŠ€èƒ½
                        found_skills = self._extract_skills_from_line(cell_str)

                    if found_skills:
                        # è®¡ç®—ä¼˜å…ˆçº§
                        score = len(found_skills)

                        # åœ¨è®¾è®¡åˆ—å·¦ä¾§çš„ä¼˜å…ˆçº§æ›´é«˜
                        if col < min_design_col:
                            score *= 2

                        # é è¿‘è®¾è®¡è¡Œçš„ä¼˜å…ˆçº§æ›´é«˜
                        distance_to_design = min(abs(row - dr) for dr in design_rows)
                        if distance_to_design <= 5:
                            score *= 1.5

                        candidates.append(
                            {
                                "row": row,
                                "col": col,
                                "found_skills": found_skills,
                                "score": score,
                            }
                        )

        if candidates:
            # é€‰æ‹©æœ€ä½³å€™é€‰
            best = max(candidates, key=lambda x: x["score"])
            print(
                f"    é€‰æ‹©æœ€ä½³ä½ç½®: [{best['row']},{best['col']}] åŒ…å«{len(best['found_skills'])}ä¸ªæŠ€èƒ½"
            )
            return best

        return None

    def _extract_skills_from_column_v2(
        self, df: pd.DataFrame, start_position: Dict
    ) -> List[str]:
        """ä»æŒ‡å®šä½ç½®æå–æŠ€èƒ½ - V2ç‰ˆæœ¬"""
        skills = []
        start_row = start_position["row"]
        start_col = start_position["col"]

        # é¦–å…ˆæå–èµ·å§‹å•å…ƒæ ¼çš„æ‰€æœ‰æŠ€èƒ½
        start_cell = df.iloc[start_row, start_col]
        if pd.notna(start_cell):
            cell_str = str(start_cell).strip()

            # å¦‚æœæ˜¯å¤šè¡Œå•å…ƒæ ¼ï¼ˆåˆå¹¶å•å…ƒæ ¼ï¼‰
            if "\n" in cell_str:
                lines = cell_str.split("\n")
                print(f"    èµ·å§‹å•å…ƒæ ¼åŒ…å«{len(lines)}è¡Œ")

                for line in lines:
                    line_skills = self._extract_skills_from_line(line)
                    skills.extend(line_skills)
            else:
                # å•è¡ŒæŠ€èƒ½
                cell_skills = self._extract_skills_from_line(cell_str)
                skills.extend(cell_skills)

        # å¦‚æœèµ·å§‹å•å…ƒæ ¼å·²ç»åŒ…å«è¶³å¤Ÿçš„æŠ€èƒ½ï¼Œå¯èƒ½ä¸éœ€è¦ç»§ç»­æœç´¢
        if len(skills) >= 5:
            print(f"    èµ·å§‹å•å…ƒæ ¼å·²åŒ…å«{len(skills)}ä¸ªæŠ€èƒ½")
            return skills

        # å¦åˆ™ç»§ç»­å‘ä¸‹æœç´¢
        for row in range(start_row + 1, min(len(df), start_row + 30)):
            found_skill_in_row = False

            # æ£€æŸ¥å½“å‰åˆ—å’Œç›¸é‚»åˆ—
            for col_offset in range(-2, 3):
                col = start_col + col_offset
                if 0 <= col < len(df.columns):
                    cell = df.iloc[row, col]
                    if pd.notna(cell):
                        cell_str = str(cell).strip()

                        # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾ç»“æŸ
                        if self._is_skill_section_end(cell_str):
                            if col == start_col:
                                return skills

                        # æå–æŠ€èƒ½
                        if "\n" in cell_str:
                            # å¤šè¡Œå•å…ƒæ ¼
                            lines = cell_str.split("\n")
                            for line in lines:
                                line_skills = self._extract_skills_from_line(line)
                                if line_skills:
                                    skills.extend(line_skills)
                                    found_skill_in_row = True
                        else:
                            # å•è¡Œ
                            cell_skills = self._extract_skills_from_line(cell_str)
                            if cell_skills:
                                skills.extend(cell_skills)
                                found_skill_in_row = True

            # å¦‚æœè¿ç»­å‡ è¡Œæ²¡æœ‰æŠ€èƒ½ï¼Œåœæ­¢æœç´¢
            if not found_skill_in_row:
                # ä½†è¦ç»§ç»­æ£€æŸ¥å‡ è¡Œï¼Œå› ä¸ºå¯èƒ½æœ‰ç©ºè¡Œ
                empty_rows = 0
                for check_row in range(row, min(row + 5, len(df))):
                    has_content = False
                    for col in range(
                        max(0, start_col - 2), min(start_col + 3, len(df.columns))
                    ):
                        if pd.notna(df.iloc[check_row, col]):
                            has_content = True
                            break
                    if not has_content:
                        empty_rows += 1

                if empty_rows >= 3:
                    break

        return skills

    def _is_valid_skill_v2(self, skill: str) -> bool:
        """éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆæŠ€èƒ½ - V2ç‰ˆæœ¬ï¼Œæ›´å®½æ¾çš„åŒ¹é…"""
        if not skill or not isinstance(skill, str):
            return False

        skill = skill.strip()

        # åŸºæœ¬æ£€æŸ¥
        if len(skill) < 1 or len(skill) > 50:
            return False

        # æ’é™¤æ˜æ˜¾ä¸æ˜¯æŠ€èƒ½çš„æ¨¡å¼
        for pattern in self.exclude_patterns:
            if re.match(pattern, skill, re.IGNORECASE):
                return False

        # ç‰¹æ®Šæƒ…å†µï¼šå•å­—ç¬¦"C"æ˜¯æœ‰æ•ˆçš„
        if skill.upper() == "C":
            return True

        # æ£€æŸ¥æ˜¯å¦åœ¨æœ‰æ•ˆæŠ€èƒ½åˆ—è¡¨ä¸­ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰
        skill_upper = skill.upper()
        for valid_skill in self.valid_skills:
            if valid_skill.upper() == skill_upper:
                return True

        # æ£€æŸ¥æ˜¯å¦åŒ…å«æŠ€æœ¯ç›¸å…³çš„å…³é”®è¯
        tech_keywords = [
            "JAVA",
            "SCRIPT",
            "SQL",
            "HTML",
            "CSS",
            "SPRING",
            "BOOT",
            "REACT",
            "VUE",
            "NODE",
            "PYTHON",
            "RUBY",
            "PHP",
        ]
        for keyword in tech_keywords:
            if keyword in skill_upper:
                return True

        # å¦‚æœåŒ…å«è‹±æ–‡å­—ç¬¦ä¸”çœ‹èµ·æ¥åƒæŠ€æœ¯åç§°
        if re.search(r"[a-zA-Z]", skill):
            # æ’é™¤ä¸€äº›æ˜æ˜¾ä¸æ˜¯æŠ€èƒ½çš„è¯
            exclude_words = ["è¨­è¨ˆ", "è£½é€ ", "è©¦é¨“", "ãƒ†ã‚¹ãƒˆ", "ç®¡ç†", "çµŒé¨“", "æ‹…å½“"]
            if not any(word in skill for word in exclude_words):
                # å¦‚æœé•¿åº¦åˆé€‚ä¸”åŒ…å«æŠ€æœ¯ç›¸å…³çš„æ¨¡å¼
                if 2 <= len(skill) <= 30:
                    return True

        return False

    def _find_design_columns(self, df: pd.DataFrame) -> List[Dict]:
        """æŸ¥æ‰¾åŸºæœ¬è¨­è¨ˆå’Œè©³ç´°è¨­è¨ˆæ‰€åœ¨çš„åˆ—"""
        design_keywords = ["åŸºæœ¬è¨­è¨ˆ", "è©³ç´°è¨­è¨ˆ", "åŸºæœ¬è®¾è®¡", "è¯¦ç»†è®¾è®¡"]
        positions = []

        # éå†æ‰€æœ‰å•å…ƒæ ¼æŸ¥æ‰¾è®¾è®¡å…³é”®è¯
        for idx in range(min(len(df), 100)):  # é™åˆ¶æœç´¢èŒƒå›´
            for col in range(len(df.columns)):
                cell = df.iloc[idx, col]
                if pd.notna(cell):
                    cell_str = str(cell).strip()
                    if any(keyword in cell_str for keyword in design_keywords):
                        positions.append({"row": idx, "col": col, "value": cell_str})

        return positions

    def _is_skill_section_end(self, cell_content: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åˆ°è¾¾æŠ€èƒ½åŒºåŸŸçš„ç»“æŸ"""
        end_markers = [
            "æ¥­å‹™å†…å®¹",
            "æ¥­å‹™å…§å®¹",
            "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ",
            "è·æ­´",
            "çµŒæ­´",
            "å®Ÿç¸¾",
            "æ‹…å½“æ¥­å‹™",
            "é–‹ç™ºå®Ÿç¸¾",
            "ä¸»ãªé–‹ç™º",
            "å‚ç”»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ",
            "ä½œæ¥­å†…å®¹",
            "æœŸé–“",
            "æ¡ˆä»¶",
            "æ¦‚è¦",
            "å·¥ç¨‹",
            "ã€",
            "â– ",
            "â—†",
            "â–¼",
            "â—ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ",
        ]

        cell_content = cell_content.strip()

        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç»“æŸæ ‡è®°
        for marker in end_markers:
            if marker in cell_content:
                return True

        # æ£€æŸ¥æ˜¯å¦æ˜¯æ—¥æœŸæ ¼å¼ï¼ˆé¡¹ç›®å¼€å§‹ï¼‰
        if re.match(r"^\d{4}[å¹´/]\d{1,2}[æœˆ/]", cell_content):
            return True

        return False

    def _extract_skills_fallback(self, df: pd.DataFrame) -> List[str]:
        """å¤‡ç”¨æŠ€èƒ½æå–æ–¹æ³•"""
        skills = []

        # å…¨æ–‡æœç´¢å·²çŸ¥æŠ€èƒ½
        text = self._dataframe_to_text(df)

        # ä½¿ç”¨æ›´å®½æ¾çš„åŒ¹é…
        for skill in self.valid_skills:
            # åˆ›å»ºå¤šç§å¯èƒ½çš„æ¨¡å¼
            patterns = [
                rf"\b{re.escape(skill)}\b",  # å®Œæ•´å•è¯è¾¹ç•Œ
                rf"(?:^|\s|[ã€,ï¼Œ]){re.escape(skill)}(?:$|\s|[ã€,ï¼Œ])",  # å¸¦åˆ†éš”ç¬¦
                rf"{re.escape(skill)}(?:[^a-zA-Z]|$)",  # åé¢ä¸æ˜¯å­—æ¯
            ]

            for pattern in patterns:
                if re.search(pattern, text, re.IGNORECASE):
                    skills.append(skill)
                    break

        return skills

    def _process_and_deduplicate_skills(self, skills: List[str]) -> List[str]:
        """å¤„ç†å’Œå»é‡æŠ€èƒ½åˆ—è¡¨"""
        final_skills = []
        seen = set()
        seen_lower = set()

        for skill in skills:
            skill = skill.strip()
            if not skill:
                continue

            # æ ‡å‡†åŒ–
            normalized = self._normalize_skill_name(skill)
            normalized_lower = normalized.lower()

            # å»é‡ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰
            if normalized_lower not in seen_lower:
                seen_lower.add(normalized_lower)
                final_skills.append(normalized)

        # æŒ‰ä¼˜å…ˆçº§æ’åº
        def skill_priority(skill):
            programming_langs = [
                "Java",
                "Python",
                "JavaScript",
                "TypeScript",
                "C",
                "C++",
                "C#",
                "PHP",
                "Ruby",
                "Go",
                "Kotlin",
                "Swift",
                "Scala",
                "Rust",
                "VB.NET",
                "VB",
                "COBOL",
            ]
            frameworks = [
                "Spring",
                "SpringBoot",
                "React",
                "Vue",
                "Angular",
                "Django",
                "Flask",
                ".NET",
                "Rails",
                "Laravel",
                "Express",
            ]
            databases = [
                "MySQL",
                "PostgreSQL",
                "Oracle",
                "SQL Server",
                "MongoDB",
                "Redis",
                "DB2",
                "SQLite",
                "Access",
            ]
            cloud_platforms = ["AWS", "Azure", "GCP"]

            if skill in programming_langs:
                return (
                    0,
                    (
                        programming_langs.index(skill)
                        if skill in programming_langs
                        else 999
                    ),
                )
            elif skill in frameworks:
                return (1, frameworks.index(skill) if skill in frameworks else 999)
            elif skill in databases:
                return (2, databases.index(skill) if skill in databases else 999)
            elif skill in cloud_platforms:
                return (
                    3,
                    cloud_platforms.index(skill) if skill in cloud_platforms else 999,
                )
            else:
                return (4, skill)

        final_skills.sort(key=skill_priority)

        print(f"    æœ€ç»ˆæå–æŠ€èƒ½æ•°é‡: {len(final_skills)}")
        return final_skills

    # ä¿ç•™æ‰€æœ‰å…¶ä»–æ–¹æ³•ä¸å˜...
    def _convert_excel_serial_to_date(
        self, serial_number: Union[int, float]
    ) -> Optional[datetime]:
        """å°†Excelåºåˆ—æ•°å­—è½¬æ¢ä¸ºæ—¥æœŸ"""
        try:
            if serial_number < 1:
                return None
            if serial_number >= 61:
                serial_number -= 1
            base_date = datetime(1900, 1, 1)
            result_date = base_date + timedelta(days=serial_number - 1)
            if 1950 <= result_date.year <= 2030:
                return result_date
        except Exception as e:
            pass
        return None

    def _extract_age_final_fix(self, all_data: List[Dict]) -> str:
        """æœ€ç»ˆä¿®å¤ç‰ˆå¹´é¾„æå–"""
        candidates = []

        for data in all_data:
            df = data["df"]

            # æ–¹æ³•1: æ‰«ææ‰€æœ‰Dateå¯¹è±¡
            for idx in range(min(30, len(df))):
                for col in range(len(df.columns)):
                    cell = df.iloc[idx, col]
                    if isinstance(cell, datetime):
                        if 1950 <= cell.year <= 2010:
                            age = self._calculate_age_from_birthdate(cell)
                            if age:
                                context_score = self._get_personal_info_context_score(
                                    df, idx, col
                                )
                                confidence = 2.0 + context_score * 0.5
                                candidates.append((str(age), confidence))

            # æ–¹æ³•2: æ‰«æExcelåºåˆ—æ—¥æœŸæ•°å­—
            for idx in range(min(30, len(df))):
                for col in range(len(df.columns)):
                    cell = df.iloc[idx, col]
                    if pd.notna(cell) and isinstance(cell, (int, float)):
                        if 18000 <= cell <= 50000:
                            converted_date = self._convert_excel_serial_to_date(cell)
                            if converted_date:
                                age = self._calculate_age_from_birthdate(converted_date)
                                if age:
                                    has_age_context = False
                                    for r_off in range(-2, 3):
                                        for c_off in range(-5, 5):
                                            r = idx + r_off
                                            c = col + c_off
                                            if 0 <= r < len(df) and 0 <= c < len(
                                                df.columns
                                            ):
                                                context_cell = df.iloc[r, c]
                                                if pd.notna(context_cell):
                                                    context_str = str(context_cell)
                                                    if any(
                                                        k in context_str
                                                        for k in [
                                                            "ç”Ÿå¹´æœˆ",
                                                            "å¹´é½¢",
                                                            "æ­³",
                                                            "æ‰",
                                                        ]
                                                    ):
                                                        has_age_context = True
                                                        break
                                        if has_age_context:
                                            break

                                    if has_age_context:
                                        confidence = 3.0
                                        candidates.append((str(age), confidence))

            # æ–¹æ³•3: ä¼ ç»Ÿçš„å¹´é¾„æ ‡ç­¾æœç´¢
            for idx in range(min(30, len(df))):
                for col in range(len(df.columns)):
                    cell = df.iloc[idx, col]
                    if pd.notna(cell):
                        cell_str = str(cell)
                        if any(k in cell_str for k in self.keywords["age"]):
                            for r_offset in range(-2, 6):
                                for c_offset in range(-2, 10):
                                    r = idx + r_offset
                                    c = col + c_offset
                                    if 0 <= r < len(df) and 0 <= c < len(df.columns):
                                        value = df.iloc[r, c]
                                        if pd.notna(value):
                                            if isinstance(value, datetime):
                                                age = (
                                                    self._calculate_age_from_birthdate(
                                                        value
                                                    )
                                                )
                                                if age:
                                                    candidates.append((str(age), 2.5))
                                            else:
                                                age = self._parse_age_value_improved(
                                                    str(value)
                                                )
                                                if age:
                                                    candidates.append((age, 2.0))

        if candidates:
            age_scores = defaultdict(float)
            for age, conf in candidates:
                age_scores[age] += conf
            best_age = max(age_scores.items(), key=lambda x: x[1])
            return best_age[0]

        return ""

    def _extract_arrival_year_final_fix(self, all_data: List[Dict]) -> Optional[str]:
        """æœ€ç»ˆä¿®å¤ç‰ˆæ¥æ—¥å¹´ä»½æå–"""
        candidates = []

        for data in all_data:
            df = data["df"]

            # æ–¹æ³•1: æ‰«ææ‰€æœ‰Dateå¯¹è±¡
            for idx in range(min(30, len(df))):
                for col in range(len(df.columns)):
                    cell = df.iloc[idx, col]
                    if isinstance(cell, datetime):
                        if 1990 <= cell.year <= 2024:
                            has_arrival_context = False
                            has_age_context = False
                            for r_off in range(-2, 3):
                                for c_off in range(-5, 5):
                                    r = idx + r_off
                                    c = col + c_off
                                    if 0 <= r < len(df) and 0 <= c < len(df.columns):
                                        context_cell = df.iloc[r, c]
                                        if pd.notna(context_cell):
                                            context_str = str(context_cell)
                                            if any(
                                                k in context_str
                                                for k in self.keywords["arrival"]
                                            ):
                                                has_arrival_context = True
                                            elif any(
                                                k in context_str
                                                for k in ["ç”Ÿå¹´æœˆ", "å¹´é½¢", "æ­³", "æ‰"]
                                            ):
                                                has_age_context = True
                                if has_arrival_context:
                                    break

                            if has_arrival_context:
                                confidence = 1.5 if has_age_context else 2.5
                                candidates.append((str(cell.year), confidence))

            # æ–¹æ³•2: æ‰«æExcelåºåˆ—æ—¥æœŸæ•°å­—
            for idx in range(min(30, len(df))):
                for col in range(len(df.columns)):
                    cell = df.iloc[idx, col]
                    if pd.notna(cell) and isinstance(cell, (int, float)):
                        if 30000 <= cell <= 50000:
                            converted_date = self._convert_excel_serial_to_date(cell)
                            if converted_date and 1990 <= converted_date.year <= 2024:
                                has_arrival_context = False
                                for r_off in range(-2, 3):
                                    for c_off in range(-5, 5):
                                        r = idx + r_off
                                        c = col + c_off
                                        if 0 <= r < len(df) and 0 <= c < len(
                                            df.columns
                                        ):
                                            context_cell = df.iloc[r, c]
                                            if pd.notna(context_cell):
                                                context_str = str(context_cell)
                                                if any(
                                                    k in context_str
                                                    for k in self.keywords["arrival"]
                                                ):
                                                    has_arrival_context = True
                                                    break
                                        if has_arrival_context:
                                            break
                                    if has_arrival_context:
                                        break

                                if has_arrival_context:
                                    confidence = 3.0
                                    candidates.append(
                                        (str(converted_date.year), confidence)
                                    )

            # æ–¹æ³•3: ä¼ ç»Ÿçš„æ¥æ—¥å…³é”®è¯æœç´¢
            for idx in range(min(40, len(df))):
                for col in range(len(df.columns)):
                    cell = df.iloc[idx, col]
                    if pd.notna(cell):
                        cell_str = str(cell)
                        if any(k in cell_str for k in self.keywords["arrival"]):
                            for r_off in range(-2, 5):
                                for c_off in range(-2, 25):
                                    r = idx + r_off
                                    c = col + c_off
                                    if 0 <= r < len(df) and 0 <= c < len(df.columns):
                                        value = df.iloc[r, c]
                                        if pd.notna(value):
                                            if isinstance(value, datetime):
                                                if 1990 <= value.year <= 2024:
                                                    candidates.append(
                                                        (str(value.year), 2.0)
                                                    )
                                            else:
                                                year = self._parse_year_value_improved(
                                                    str(value)
                                                )
                                                if year:
                                                    candidates.append((year, 1.8))

        if candidates:
            year_scores = defaultdict(float)
            for year, conf in candidates:
                year_scores[year] += conf
            if year_scores:
                best_year = max(year_scores.items(), key=lambda x: x[1])
                return best_year[0]

        return None

    def _extract_nationality_final_fix(self, all_data: List[Dict]) -> Optional[str]:
        """æœ€ç»ˆä¿®å¤ç‰ˆå›½ç±æå–"""
        valid_nationalities = [
            "ä¸­å›½",
            "æ—¥æœ¬",
            "éŸ“å›½",
            "ãƒ™ãƒˆãƒŠãƒ ",
            "ãƒ•ã‚£ãƒªãƒ”ãƒ³",
            "ã‚¤ãƒ³ãƒ‰",
            "ãƒãƒ‘ãƒ¼ãƒ«",
            "ã‚¢ãƒ¡ãƒªã‚«",
            "ãƒ–ãƒ©ã‚¸ãƒ«",
            "å°æ¹¾",
            "ã‚¿ã‚¤",
            "ã‚¤ãƒ³ãƒ‰ãƒã‚·ã‚¢",
            "ãƒãƒ³ã‚°ãƒ©ãƒ‡ã‚·ãƒ¥",
            "ã‚¹ãƒªãƒ©ãƒ³ã‚«",
            "ãƒŸãƒ£ãƒ³ãƒãƒ¼",
            "ã‚«ãƒ³ãƒœã‚¸ã‚¢",
            "ãƒ©ã‚ªã‚¹",
            "ãƒ¢ãƒ³ã‚´ãƒ«",
        ]

        candidates = []

        for data in all_data:
            df = data["df"]

            # æ–¹æ³•1: æ‰«ææ•´ä¸ªè¡¨æ ¼çš„æ‰€æœ‰å›½ç±å…³é”®è¯
            for idx in range(min(50, len(df))):
                for col in range(len(df.columns)):
                    cell = df.iloc[idx, col]
                    if pd.notna(cell):
                        cell_str = str(cell).strip()

                        # ç›´æ¥æ£€æŸ¥æ˜¯å¦æ˜¯å›½ç±å€¼
                        if cell_str in valid_nationalities:
                            # è®¡ç®—ä¸Šä¸‹æ–‡è¯„åˆ†
                            context_score = 0

                            # æ£€æŸ¥åŒè¡Œæ˜¯å¦æœ‰ä¸ªäººä¿¡æ¯
                            row_data = df.iloc[idx]
                            row_text = " ".join(
                                [str(cell) for cell in row_data if pd.notna(cell)]
                            )
                            if any(
                                keyword in row_text
                                for keyword in [
                                    "æ°å",
                                    "æ€§åˆ¥",
                                    "å¹´é½¢",
                                    "æœ€å¯„",
                                    "ä½æ‰€",
                                    "ç”·",
                                    "å¥³",
                                ]
                            ):
                                context_score += 2.0

                            # æ£€æŸ¥å‘¨å›´æ˜¯å¦æœ‰ä¸ªäººä¿¡æ¯
                            for r_off in range(-3, 4):
                                for c_off in range(-5, 6):
                                    r = idx + r_off
                                    c = col + c_off
                                    if 0 <= r < len(df) and 0 <= c < len(df.columns):
                                        nearby_cell = df.iloc[r, c]
                                        if pd.notna(nearby_cell):
                                            nearby_text = str(nearby_cell)
                                            if any(
                                                keyword in nearby_text
                                                for keyword in [
                                                    "æ°å",
                                                    "æ€§åˆ¥",
                                                    "å¹´é½¢",
                                                    "å­¦æ­´",
                                                ]
                                            ):
                                                context_score += 1.0

                            total_confidence = max(1.0, context_score)
                            candidates.append((cell_str, total_confidence))

            # æ–¹æ³•2: æŸ¥æ‰¾å›½ç±æ ‡ç­¾é™„è¿‘çš„å€¼
            for idx in range(min(40, len(df))):
                for col in range(len(df.columns)):
                    cell = df.iloc[idx, col]
                    if pd.notna(cell) and any(
                        k in str(cell) for k in self.keywords["nationality"]
                    ):
                        for r_off in range(-3, 6):
                            for c_off in range(-3, 15):
                                r = idx + r_off
                                c = col + c_off
                                if 0 <= r < len(df) and 0 <= c < len(df.columns):
                                    value = df.iloc[r, c]
                                    if pd.notna(value):
                                        value_str = str(value).strip()
                                        if value_str in valid_nationalities:
                                            confidence = 3.0
                                            candidates.append((value_str, confidence))

        if candidates:
            nationality_scores = defaultdict(float)
            for nationality, conf in candidates:
                nationality_scores[nationality] += conf
            if nationality_scores:
                best_nationality = max(nationality_scores.items(), key=lambda x: x[1])
                return best_nationality[0]

        return None

    def _extract_experience_final_fix(self, all_data: List[Dict]) -> str:
        """æœ€ç»ˆä¿®å¤ç‰ˆç»éªŒæå–"""
        candidates = []

        for data in all_data:
            df = data["df"]

            # æ–¹æ³•1: æŸ¥æ‰¾ç»éªŒå…³é”®è¯
            for idx in range(min(60, len(df))):
                for col in range(len(df.columns)):
                    cell = df.iloc[idx, col]
                    if pd.notna(cell):
                        cell_str = str(cell)
                        if any(k in cell_str for k in self.keywords["experience"]):
                            # æ’é™¤è¯´æ˜æ–‡å­—
                            if any(
                                ex in cell_str
                                for ex in [
                                    "ä»¥ä¸Š",
                                    "æœªæº€",
                                    "â—",
                                    "â—‹",
                                    "â–³",
                                    "æŒ‡å°",
                                    "ç²¾é€š",
                                    "ã§ãã‚‹",
                                ]
                            ):
                                continue

                            # æœç´¢æ•°å€¼
                            for r_off in range(-3, 6):
                                for c_off in range(-3, 30):
                                    r = idx + r_off
                                    c = col + c_off
                                    if 0 <= r < len(df) and 0 <= c < len(df.columns):
                                        value = df.iloc[r, c]
                                        if pd.notna(value):
                                            exp = self._parse_experience_value(
                                                str(value)
                                            )
                                            if exp:
                                                confidence = 1.0

                                                # æ ¹æ®å…³é”®è¯ç±»å‹è°ƒæ•´ç½®ä¿¡åº¦
                                                if "ã‚½ãƒ•ãƒˆé–¢é€£æ¥­å‹™çµŒé¨“å¹´æ•°" in cell_str:
                                                    confidence *= 3.0
                                                elif "ITçµŒé¨“å¹´æ•°" in cell_str:
                                                    confidence *= 2.5
                                                elif "å®Ÿå‹™çµŒé¨“" in cell_str:
                                                    confidence *= 2.0

                                                candidates.append((exp, confidence))

            # æ–¹æ³•2: ä»é¡¹ç›®æ—¥æœŸæ¨ç®—ç»éªŒ
            for idx in range(min(50, len(df))):
                for col in range(len(df.columns)):
                    cell = df.iloc[idx, col]
                    if isinstance(cell, datetime):
                        # æ£€æŸ¥æ˜¯å¦æ˜¯é¡¹ç›®å¼€å§‹æ—¥æœŸï¼ˆå¯ä»¥æ¨ç®—ç»éªŒï¼‰
                        if 2015 <= cell.year <= 2024:
                            # æ£€æŸ¥åŒè¡Œæ˜¯å¦æœ‰é¡¹ç›®æè¿°
                            row_data = df.iloc[idx]
                            row_text = " ".join(
                                [str(cell) for cell in row_data if pd.notna(cell)]
                            )
                            if any(
                                keyword in row_text
                                for keyword in [
                                    "ã‚·ã‚¹ãƒ†ãƒ ",
                                    "é–‹ç™º",
                                    "æ¥­å‹™",
                                    "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ",
                                ]
                            ):
                                # ä»æœ€æ—©çš„é¡¹ç›®æ—¥æœŸæ¨ç®—ç»éªŒå¹´æ•°
                                experience_years = 2024 - cell.year
                                if 1 <= experience_years <= 15:
                                    # å¯¹äºåˆç†çš„é¡¹ç›®ç»éªŒï¼Œç»™äºˆæ›´é«˜ç½®ä¿¡åº¦
                                    confidence = 1.5 if experience_years >= 5 else 1.2
                                    exp_str = f"{experience_years}å¹´"
                                    candidates.append((exp_str, confidence))

        if candidates:
            candidates.sort(key=lambda x: x[1], reverse=True)
            result = candidates[0][0].translate(self.trans_table)
            return result

        return ""

    def _calculate_age_from_birthdate(self, birthdate: datetime) -> Optional[int]:
        """ä»ç”Ÿå¹´æœˆæ—¥è®¡ç®—å¹´é¾„"""
        try:
            current_date = datetime(2024, 11, 1)
            age = current_date.year - birthdate.year
            if (current_date.month, current_date.day) < (
                birthdate.month,
                birthdate.day,
            ):
                age -= 1
            if 15 <= age <= 75:
                return age
        except:
            pass
        return None

    def _parse_age_value_improved(self, value: str) -> Optional[str]:
        """æ”¹è¿›çš„å¹´é¾„å€¼è§£æ"""
        value = str(value).strip()
        if len(value) > 15 or "å¹´æœˆ" in value or "è¥¿æš¦" in value or "19" in value:
            return None

        # å¤„ç†"æº€"å­—æ ¼å¼
        match = re.search(r"æº€\s*(\d{1,2})\s*[æ­³æ‰]", value)
        if match:
            age = int(match.group(1))
            if 18 <= age <= 65:
                return str(age)

        # ä¼˜å…ˆåŒ¹é…åŒ…å«"æ­³"æˆ–"æ‰"çš„
        match = re.search(r"(\d{1,2})\s*[æ­³æ‰]", value)
        if match:
            age = int(match.group(1))
            if 18 <= age <= 65:
                return str(age)

        # å°è¯•æå–çº¯æ•°å­—
        match = re.search(r"^(\d{1,2})$", value)
        if match:
            age = int(match.group(1))
            if 18 <= age <= 65:
                return str(age)

        return None

    def _parse_year_value_improved(self, value: str) -> Optional[str]:
        """æ”¹è¿›çš„å¹´ä»½å€¼è§£æ"""
        value_str = str(value).strip()

        # ç›´æ¥çš„å¹´ä»½æ ¼å¼
        if re.match(r"^20\d{2}$", value_str):
            return value_str

        # å¹´æœˆæ ¼å¼
        match = re.search(r"(20\d{2})[å¹´/æœˆ]", value_str)
        if match:
            return match.group(1)

        # 2016å¹´4æœˆæ ¼å¼
        match = re.search(r"(20\d{2})å¹´\d+æœˆ", value_str)
        if match:
            return match.group(1)

        # å’Œæš¦
        if "å¹³æˆ" in value_str:
            match = re.search(r"å¹³æˆ\s*(\d+)", value_str)
            if match:
                return str(1988 + int(match.group(1)))
        elif "ä»¤å’Œ" in value_str:
            match = re.search(r"ä»¤å’Œ\s*(\d+)", value_str)
            if match:
                return str(2018 + int(match.group(1)))

        return None

    def _get_personal_info_context_score(
        self, df: pd.DataFrame, row: int, col: int
    ) -> float:
        """è·å–ä¸ªäººä¿¡æ¯ä¸Šä¸‹æ–‡è¯„åˆ†"""
        score = 0.0
        personal_keywords = (
            self.keywords["name"]
            + self.keywords["gender"]
            + self.keywords["age"]
            + ["å­¦æ­´", "æœ€çµ‚å­¦æ­´", "ä½æ‰€", "æœ€å¯„é§…", "æœ€å¯„", "çµŒé¨“", "å®Ÿå‹™"]
        )

        for r in range(max(0, row - 3), min(len(df), row + 4)):
            for c in range(max(0, col - 5), min(len(df.columns), col + 6)):
                cell = df.iloc[r, c]
                if pd.notna(cell):
                    cell_str = str(cell)
                    for keyword in personal_keywords:
                        if keyword in cell_str:
                            score += 1.0

        return score

    # ä¿ç•™åŸæœ‰çš„å…¶ä»–æ–¹æ³•
    def _extract_name(self, all_data: List[Dict]) -> str:
        """æå–å§“å"""
        candidates = []

        for data in all_data:
            df = data["df"]

            for idx in range(min(20, len(df))):
                for col in range(len(df.columns)):
                    cell = df.iloc[idx, col]
                    if pd.notna(cell) and any(
                        k in str(cell) for k in self.keywords["name"]
                    ):
                        for r_offset in range(-2, 5):
                            for c_offset in range(-2, 15):
                                r = idx + r_offset
                                c = col + c_offset
                                if 0 <= r < len(df) and 0 <= c < len(df.columns):
                                    value = df.iloc[r, c]
                                    if pd.notna(value) and self._is_valid_name(
                                        str(value)
                                    ):
                                        confidence = 1.0
                                        if r == idx:
                                            confidence *= 1.5
                                        if c > col and c - col <= 5:
                                            confidence *= 1.3
                                        candidates.append(
                                            (str(value).strip(), confidence)
                                        )

        if candidates:
            candidates.sort(key=lambda x: x[1], reverse=True)
            return candidates[0][0]
        return ""

    def _extract_gender(self, all_data: List[Dict]) -> Optional[str]:
        """æå–æ€§åˆ«"""
        for data in all_data:
            df = data["df"]

            for idx in range(min(30, len(df))):
                for col in range(len(df.columns)):
                    cell = df.iloc[idx, col]
                    if pd.notna(cell):
                        cell_str = str(cell).strip()

                        if cell_str in ["ç”·", "ç”·æ€§"]:
                            if self._has_nearby_keyword(
                                df, idx, col, self.keywords["gender"], radius=5
                            ):
                                return "ç”·æ€§"
                        elif cell_str in ["å¥³", "å¥³æ€§"]:
                            if self._has_nearby_keyword(
                                df, idx, col, self.keywords["gender"], radius=5
                            ):
                                return "å¥³æ€§"
                        elif any(k in cell_str for k in self.keywords["gender"]):
                            for r_off in range(-2, 3):
                                for c_off in range(-2, 10):
                                    r = idx + r_off
                                    c = col + c_off
                                    if 0 <= r < len(df) and 0 <= c < len(df.columns):
                                        value = df.iloc[r, c]
                                        if pd.notna(value):
                                            v_str = str(value).strip()
                                            if v_str in ["ç”·", "ç”·æ€§", "M", "Male"]:
                                                return "ç”·æ€§"
                                            elif v_str in ["å¥³", "å¥³æ€§", "F", "Female"]:
                                                return "å¥³æ€§"
        return None

    def _extract_japanese_level(self, all_data: List[Dict]) -> str:
        """æå–æ—¥è¯­æ°´å¹³"""
        candidates = []

        for data in all_data:
            text = data["text"]
            df = data["df"]

            jlpt_patterns = [
                (r"JLPT\s*[Nnï¼®]([1-5ï¼‘-ï¼•])", 2.0),
                (r"[Nnï¼®]([1-5ï¼‘-ï¼•])\s*(?:åˆæ ¼|å–å¾—|ãƒ¬ãƒ™ãƒ«|ç´š)", 1.8),
                (r"æ—¥æœ¬èªèƒ½åŠ›è©¦é¨“\s*[Nnï¼®]?([1-5ï¼‘-ï¼•])\s*ç´š?", 1.5),
                (r"(?:^|\s)[Nnï¼®]([1-5ï¼‘-ï¼•])(?:\s|$|[\(ï¼ˆ])", 1.0),
                (r"æ—¥æœ¬èª.*?([ä¸€äºŒä¸‰å››äº”])ç´š", 1.3),
                (r"([ä¸€äºŒä¸‰å››äº”])ç´š.*?æ—¥æœ¬èª", 1.3),
            ]

            for pattern, confidence in jlpt_patterns:
                matches = re.finditer(pattern, text, re.IGNORECASE | re.MULTILINE)
                for match in matches:
                    level_str = match.group(1)
                    kanji_to_num = {
                        "ä¸€": "1",
                        "äºŒ": "2",
                        "ä¸‰": "3",
                        "å››": "4",
                        "äº”": "5",
                    }
                    if level_str in kanji_to_num:
                        level_num = kanji_to_num[level_str]
                    else:
                        level_num = level_str.translate(self.trans_table)
                    level = f"N{level_num}"
                    candidates.append((level, confidence))

            if "ãƒ“ã‚¸ãƒã‚¹" in text and any(jp in text for jp in ["æ—¥æœ¬èª", "æ—¥èª"]):
                candidates.append(("ãƒ“ã‚¸ãƒã‚¹ãƒ¬ãƒ™ãƒ«", 0.8))
            elif "ä¸Šç´š" in text and any(jp in text for jp in ["æ—¥æœ¬èª", "æ—¥èª"]):
                candidates.append(("ä¸Šç´š", 0.8))
            elif "ä¸­ç´š" in text and any(jp in text for jp in ["æ—¥æœ¬èª", "æ—¥èª"]):
                candidates.append(("ä¸­ç´š", 0.7))

        if candidates:
            candidates.sort(key=lambda x: x[1], reverse=True)
            return candidates[0][0]
        return ""

    def _normalize_skill_name(self, skill: str) -> str:
        skill = skill.strip()
        skill_mapping = {
            "JAVA": "Java",
            "java": "Java",
            "Javascript": "JavaScript",
            "javascript": "JavaScript",
            "JAVASCRIPT": "JavaScript",
            "MySql": "MySQL",
            "mysql": "MySQL",
            "Intellij": "IntelliJ",
            "intellij": "IntelliJ",
            "Junit": "JUnit",
            "junit": "JUnit",
            "python": "Python",
            "React.js": "React",
            "Vue.js": "Vue",
            "Node.JS": "Node.js",
            "node.js": "Node.js",
            "LINUX": "Linux",
            "linux": "Linux",
            "UNIX": "Unix",
            "unix": "Unix",
            "ORACLE": "Oracle",
            "oracle": "Oracle",
            "eclipse": "Eclipse",
            "spring": "Spring",
            "springboot": "SpringBoot",
            "SpringBoot": "SpringBoot",
            "postman": "Postman",
            "git": "Git",
            "github": "GitHub",
            "struct2": "Struts2",
            "PG": "PostgreSQL",
            "JS": "JavaScript",
            "ï¼¯ï¼³": "OS",
            "ï¼¤ï¼¢": "DB",
            "Jquery": "jQuery",
            "jquery": "jQuery",
            "JBOSS": "JBoss",
            "jboss": "JBoss",
            "SqlServer": "SQL Server",
            "sqlserver": "SQL Server",
            "Form Desigener": "Form Designer",
            "win10": "Windows 10",
            "Win10": "Windows 10",
        }
        if skill in skill_mapping:
            return skill_mapping[skill]
        skill_lower = skill.lower()
        for k, v in skill_mapping.items():
            if k.lower() == skill_lower:
                return v
        skill = re.sub(r"\s+", " ", skill)
        if "ï¼¯ï¼³" in skill:
            skill = skill.replace("ï¼¯ï¼³", "OS")
        if "ï¼¤ï¼¢" in skill:
            skill = skill.replace("ï¼¤ï¼¢", "DB")
        if skill in self.valid_skills:
            return skill
        for valid_skill in self.valid_skills:
            if valid_skill.lower() == skill_lower:
                return valid_skill
        return skill

    def _is_skill_mark(self, value) -> bool:
        if pd.isna(value):
            return False
        value_str = str(value).strip()
        return value_str in self.skill_marks

    def _is_valid_name(self, name: str) -> bool:
        name = str(name).strip()
        exclude_words = [
            "æ°å",
            "åå‰",
            "ãƒ•ãƒªã‚¬ãƒŠ",
            "æ€§åˆ¥",
            "å¹´é½¢",
            "å›½ç±",
            "ç”·",
            "å¥³",
            "æ­³",
            "æ‰",
            "çµŒé¨“",
            "è³‡æ ¼",
            "å­¦æ­´",
            "ä½æ‰€",
            "é›»è©±",
            "ãƒ¡ãƒ¼ãƒ«",
            "ç¾åœ¨",
            "ã‚¹ã‚­ãƒ«ã‚·ãƒ¼ãƒˆ",
            "å±¥æ­´æ›¸",
            "è·å‹™çµŒæ­´æ›¸",
            "æŠ€è¡“",
            "å¹´æœˆ",
            "ç”Ÿå¹´æœˆ",
        ]
        for word in exclude_words:
            if word in name:
                return False
        if len(name) < 2 or len(name) > 15:
            return False
        if name.replace(" ", "").replace("ã€€", "").isdigit():
            return False
        if not re.search(r"[ä¸€-é¾¥ã-ã‚“ã‚¡-ãƒ³a-zA-Z]", name):
            return False
        if re.match(r"^[A-Z]{2,4}$", name):
            return True
        if " " in name or "ã€€" in name:
            parts = re.split(r"[\sã€€]+", name)
            if len(parts) == 2 and all(len(p) >= 1 for p in parts):
                return True
        return True

    def _parse_experience_value(self, value: str) -> Optional[str]:
        value = str(value).strip()
        if any(exclude in value for exclude in ["ä»¥ä¸Š", "æœªæº€", "â—", "â—‹", "â–³", "çµŒé¨“"]):
            return None
        value = value.translate(self.trans_table)
        patterns = [
            (
                r"^(\d+)\s*å¹´\s*(\d+)\s*ãƒ¶æœˆ$",
                lambda m: f"{m.group(1)}å¹´{m.group(2)}ãƒ¶æœˆ",
            ),
            (
                r"^(\d+(?:\.\d+)?)\s*å¹´$",
                lambda m: (
                    f"{float(m.group(1)):.0f}å¹´"
                    if float(m.group(1)) == int(float(m.group(1)))
                    else f"{m.group(1)}å¹´"
                ),
            ),
            (
                r"^(\d+(?:\.\d+)?)\s*$",
                lambda m: (
                    f"{float(m.group(1)):.0f}å¹´"
                    if 1 <= float(m.group(1)) <= 40
                    else None
                ),
            ),
            (r"(\d+)\s*å¹´\s*(\d+)\s*ãƒ¶æœˆ", lambda m: f"{m.group(1)}å¹´{m.group(2)}ãƒ¶æœˆ"),
            (r"(\d+)\s*å¹´", lambda m: f"{m.group(1)}å¹´"),
        ]
        for pattern, formatter in patterns:
            match = re.search(pattern, value)
            if match:
                result = formatter(match)
                if result:
                    return result
        return None

    def _has_nearby_keyword(
        self, df: pd.DataFrame, row: int, col: int, keywords: List[str], radius: int = 5
    ) -> bool:
        for r in range(max(0, row - radius), min(len(df), row + radius + 1)):
            for c in range(
                max(0, col - radius), min(len(df.columns), col + radius + 1)
            ):
                cell = df.iloc[r, c]
                if pd.notna(cell) and any(k in str(cell) for k in keywords):
                    return True
        return False

    def _dataframe_to_text(self, df: pd.DataFrame) -> str:
        text_parts = []
        for idx, row in df.iterrows():
            row_text = " ".join([str(cell) for cell in row if pd.notna(cell)])
            if row_text.strip():
                text_parts.append(row_text)
        return "\n".join(text_parts)


# æµ‹è¯•å‡½æ•°
if __name__ == "__main__":
    extractor = FinalFixResumeExtractor()

    test_files = [
        "ã‚¹ã‚­ãƒ«ã‚·ãƒ¼ãƒˆ_ryu.xlsx",  # é‡ç‚¹æµ‹è¯•è¿™ä¸ªæ–‡ä»¶çš„æŠ€èƒ½æå–
        "æ¥­å‹™çµŒæ­´æ›¸_ FYY_é‡‘ç”ºé§….xlsx",
        "ã‚¹ã‚­ãƒ«ã‚·ãƒ¼ãƒˆGT.xlsx",
    ]

    for file in test_files:
        print(f"\n{'='*60}")
        print(f"ğŸ”§ æœ€ç»ˆä¿®å¤æµ‹è¯•æ–‡ä»¶V2: {file}")
        print("=" * 60)

        try:
            result = extractor.extract_from_excel(file)

            if "error" not in result:
                print(f"\nâœ… æå–ç»“æœ:")
                print(f"   å§“å: {result['name']}")
                print(f"   æ€§åˆ«: {result['gender']}")
                print(f"   å¹´é¾„: {result['age']}")
                print(f"   å›½ç±: {result['nationality']}")
                print(f"   æ¥æ—¥å¹´ä»½: {result['arrival_year_japan']}")
                print(f"   ç»éªŒ: {result['experience']}")
                print(f"   æ—¥è¯­: {result['japanese_level']}")
                print(f"   æŠ€èƒ½({len(result['skills'])}ä¸ª): ")

                # åˆ†ç»„æ˜¾ç¤ºæŠ€èƒ½
                if result["skills"]:
                    # å‰10ä¸ªæŠ€èƒ½
                    print(f"     ä¸»è¦æŠ€èƒ½: {', '.join(result['skills'][:10])}")
                    if len(result["skills"]) > 10:
                        print(f"     å…¶ä»–æŠ€èƒ½: {', '.join(result['skills'][10:20])}")
                        if len(result["skills"]) > 20:
                            print(f"     ... è¿˜æœ‰ {len(result['skills']) - 20} ä¸ªæŠ€èƒ½")

                print("\nğŸ“‹ JSONæ ¼å¼:")
                print(json.dumps(result, ensure_ascii=False, indent=2))
            else:
                print(f"âŒ é”™è¯¯: {result['error']}")
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
            import traceback

            traceback.print_exc()
